--MS_Obsidian_Superfast_Starfleet_Random_Bounded_Frequency_Integer_Or_Hash_ID_Generator
--With this algorithm, you're generating integer string hashes, comprised of single digit integer numbers (0 to 9), where each digit is indexed from a scrambled and deconstructed number partition, with p (pi) itself providing the necessary decimal sequence predicate for the partitioning regime (which is itself an irrational, class-balanced, almost certainly 'fully' randomicit, number, with an infinite decimal precision limit {so long as you don't run out of atoms in the universe to store it with}... This gives the algorithm theoretically 'infinite virtual potential')... As a result, the combinatorial search space for each digit of a generated Starfleet Integer Hash ID, is linearly proportional to its character length, as follows:
--GENERAL COMBINATORIAL COMPLEXITY CALCULATION : (10 (single digit integer range) ^40 (typical digit hash length)) x 10^8 (Terran seed range {currently limited by the data type decimal precision in SQL Server}) x 10^8 (Vulcan seed range {currently limited by the data type decimal precision in SQL Server}) x 10^8 (Andorian seed range {currently limited by the data type decimal precision in SQL Server}) x 10^1 (maximum hash shift positions {currently limited by the data type decimal precision in SQL Server}) x 10^1 (space dilation {dimensional pillar delta}) x 10^1 (temporal distortion {system state clocking}) = 10^67... This is an extremely large number, much larger than a VI(R)GINTILLION in short-scale naming... In other words, insanely complex (and that's completely ignoring the fact that it is derived from a completely random foundation sequence)... No one is ever going to ever be able to cyber-hack this algorithm in any kind of reasonable (and I would say even significantly fictitious) reality, providing you don't do something really stupid with its application to your problem context...
--As you can probably tell by now therefore, ChatGPT thinks that this is a very random number generator indeed!!!... Please be aware though, that cyber security is only ensured, so long as @Hash_Seeds (All of Terran, Vulcan, and Andorian) are kept private (and to be honest, you probably want to keep all the assigned global variable values private, for the same reason!!!)...
--'Keep your eyes peeled' (Non-Andorians only of course... Wouldn't want to offend their Augur-Prime) for an additional temporal distortion technique (THIS IS NOW IMPLEMENTED IN THE ALGORITH!!!)... Used to be releasing anytime soon!!!... It will hopefully mean that even if somehow a cyber adversary obtained your @Hash_Seeds, the additional calculations needed to temporally anti-distort the generated hashes would be so obscene in both count size and compute size (you would need to have monitored the exact CPU state and timings of each computation, which is most intractable to say the least, even for insiders like Starfleet engineers), that simply put, no one would ever actually 'bother you' about it... They would essentially be searching an infinitessimal part of the combinatorial search space, for half of 'universal eternity', and making no progress... Kinda like a Terran trying to explain euphoria to a vulcan with much badly hidden schadenfreude, and then realising with excruciating abasement, that upon talking to your average Andorian later that evening, Terran euphoria is like comatosis in comparison to Andorian 'Raptulation'!!!... What is more, the dilation of the time-space continuum (see later in this algorithm) which occurs when using this algorithm, has been theorised as the source of Bynar free-will... It may actually boost the combinatorial search space up to (10^40)^10) or 10^400, which gives Bynars the ability to make anywhere up to ten centillion possible decision variants in their lifetime!!!... They claim that Terrans enjoy considerably less largesse, and for obvious reasons, no hate intended!!!... Don't quote me on these stats (I can't be bothered to actually work them out... Besides, there is a conceptual and philosophical debate yet to be had, surrounding the difference between combinatorial and complexial algorithm stats!!!)

--Please note, that the reason I have chosen the Pi number as the basis of randomicity is as follows:
--The digits of p (pi) are basically the universe's best 'foundationally intrinsic' attempt to provide mankind with the perfect random sequence generator.. Here’s a breakdown of why:
--1. p (pi) is Deterministic --> Which is necessary, in order to actually compute a reliable output.
--2. The classes of p (pi) are Uniformly Distributed --> This means that in the known decimal expansions, each digit (0 to 9) appears roughly equally often.
--3. The sequence of p (pi) digits is Statistically Random --> Ideal, because there are no obvious meta-patterns that repetitively occur.
--4. The limit of p (pi) is Normal --> Basically indicating, that its infinite decimal expansion will propagate the first three properties with the utmost fidelity.
--5. Simulated Chaos arising from deconstructed p (pi) derivations --> Should however, mean that small changes in global variables, can emulate maximally possible quantum-random behaviour on digital hardware.
--In conclusion, I would stop using all other random integer generators pronto, and come join +Raphael+ in the superiority-takes-all space conquest... It starts with Terran-operated bases on the moon this decade, and is quickly followed up by speciating-humanoid colonies on Mars, this half century!!!

--Please note, that during very minimal testing, repeated executions of the query, while temporal distortion was engaged, sometimes generated the same Hash IDs... I can only imagine that this is because query caching is turned on... Please remember to disable query caching for this algorithm, if you are using temporal distortion features!!!... Of course, once the query has cached as temporally distorted, and you amend the associated toolean global variables, query caching will likely also adversely affect the desired output from the algorithm... SO PLEASE ALWAYS TURN OFF QUERY CACHING INFACT!!!
--Also, please note, that due to SQL Server data type precision and clock timing precision shortcomings, both hashes and numbers that are served, do not include the capability of varying across the single most precsise digit ('ones')... In practice, this means we are waiting on Microsoft to improve SQL Server precision in order to unlock full and true pseudo-quantum randomicity generation... For now, if you use the algorithm, you will only experience randomicit granularity every 10 degrees of algorithmic freedom (ie_ every ten consecutive integer numbers on the 100,000,000 range scale {as the numbers inbetween will not currently be modelled})... This invariability is actually nugatory, because the number 10 is so small compared to 100,000,000, and so will simply be almost always rounded out of effect...

--I now consider this algorithm functionally complete, in terms of being able to model any kind of randomicit series of Hash IDs / Numbers / Labels (You would simply use a Replace() function on the resulting random numbers, which correspond to your label classes {provided you have set the range bounds appropriately})... As such, if the functionality that you believe you require doesn't exist in this algorithm, you are probably trying to generate randomicity for the wrong reasons!!!
--I also have theories regarding next-generation completely-superior advanced usecases for random number generators (algorithm blueprints designed already)... More on this, once I get a job or a customer...
--One idea I will providing a solution for can be called something like Native Augmentable Physics Simulation (NAPS)... This is a trick I learned from Master Jedi 'Yoda the Best' himself!!!

--NOTA BENE 0001: Please be aware, that the hashes produced by this algorithm, can be directly used in order to encrypt any data... You would simply generate an array of frequency-balanced random numbers which are range bounded from zero (0) to two hundred and fifty five (255) both inclusive, the row count of the array being equal to the length of the number of characters of data you want to encrypt... Then offset each charcter (by index) in your data string, by its corresponding row (by order) of the frequency-balanced random range bounded array output. When you have done this, no one will be able to decrypt the offset/encrypted data hash, without knowing the global variable settings you used in order to generate the array of range bounded offset values between zero (0) and two hundred and fifty five (255)... BTW, the zero to 255 is the standard set of ASCII characters, which this algorithm has been designed to accommodate (although you could theoretically use any character or symbol set of your choosing)... I call this encryption technique: PIO Encryption... (PI representing the number Pi, and the letter O standing for Obsidian... Also of course St Pio being one of my favourite saints)... Oh, and finally on thihs point, please be aware that offsetting can be done one of three ways: 1. Character-Positional - Where the characters in the data input are re-arranged (This is probably not viable, because hackers could in some cases infer what kind of data is encrypted, simply by deducing character frequencies); 2. Character-Valual - Industrial-Grade very strong encryption, but also very efficient, as the offsetting is done by simply adding a 'wrap-back-around-to-zero' ASCII code number to each existing character ASCII code number in the input data, with no positional swapping necessary (This requires first converting your input string data into ASCII codes, doing the value offsett, and then converting back to corresponding offset string characters); 3. A combination of Character-positional and character-valual (Which would obviously provide the greatest encryption strength, but in my honest opinion, there is already no way to crack the valual approach on its own, without brute-forcing (which has been demonstrated as being completely infeasible given eventual complexety values of at least {10 ^ 50}), so why bother with the extra positional compute unless your have some form of mild OCD?... and I do pray for OCD sufferers every day, implicitly)
--NOTA BENE 0002: Please also be aware, that this algorithm currently has a complexity maxima of around (10 ^ 50)... This may not be cryptographically sufficient, going forward beyond this century, expecting massive digital computational advances over the interveneing years... However, I am currently working on a version of the algorithm which will essentially enable psuedo-infinite capability to increase hashing complexity, as the user chooses, such that at no future date, will it be possible to break encryption, no matter what kind of computational technology is developed (including even massive quantum compute)... Keep watching my GitHub site for the next few days and weeks...
--NOTA BENE 0003: If you are using this algorithm to PIO Encrypt your data, please make sure that you add padding wherever necessary, such that random characters are inserted inbetween each character of your input data, either during or after hashing, such that the output hash is at least 3,000 characters long... I have chosen this number, in order to avoid any possible near-term brute force hacking vulnerability of the encryption hashes... Oh, and I will be implementing and uploading this full and optimised PIO Encryption technique as well, within the next few days or weeks...
--NOTA BENE 0004: I acknowledge that there is still the big problem of public key exchange, when starting a new set of communications between two parties over the internet or some other public medium of exchange in the future... This will be addressed within the next few months or years... I have some very abstract ideas, and will play around, come dragons dirge later this year!!!...
--NOTA BENE 0005: Know too, that other random number decompositions could be used as the basis for randomicity, instead of Pi...
--NOTA BENE 0006: One major SQL Server specific usecase for the Pio ancryption algorithm (to be released soon), is 'in-database at-rest data-encryption'... Also note, public Key distribution is hopefully also eventually on its way!!!...

--(NECESSARY METAVARIABLE SETTINGS)
--I would like a setting to turn of query caching for all plans in this query, without having to specify for individual statements, and I certainly don't want to turn of query plans for the whole database... Come on Microsoft... Why have you not already enabled this functionality???... It seems pretty universally useful!!!...


--(GLOBAL VARIABLES)
-->>>>>>>>>>>>>>>>> EVERY TIME YOU EXECUTE THIS ALGORITHM, PLEASE AT A MINIMUM, REMEMBER TO CHECK THAT THESE THREE VARIABLES ARE SET CORRECTLY BELOW, IN THE APPROPRIATE ASSIGNATION CODEBLOCK!!!!!
--1. Temporal_Distortion_Boolean
--2. Range_Bounded_Number_Generation_Boolean
--3. Range_Bound_Frequency_Boolean
--<<<<<<<<<<<<<<<<<  EVERY TIME YOU EXECUTE THIS ALGORITHM, PLEASE AT A MINIMUM, REMEMBER TO CHECK THAT THESE THREE VARIABLES ARE SET CORRECTLY BELOW BELOW, IN THE APPROPRIATE ASSIGNATION CODEBLOCK!!!!!

--1. Other Variables
Declare @Core_Algorithmic_Decimal_Data_Type_Precision As Bigint
Set @Core_Algorithmic_Decimal_Data_Type_Precision = 100000000 --100 Million (in SQL Server 2022 {currently maximum viable precision given that we want fully assignable digits [0 through 9 for each], and plus one seing as we need to round indexes up rather than down})... Adjust this accordingl,y if you implement this algorithm with greater decimal data type precision...

Declare @Core_Algorithmic_CPU_Clock_Digit_Precision As Bigint
Set @Core_Algorithmic_CPU_Clock_Digit_Precision = 8 --8 (in SQL Server 2022 {currently maximum viable precision})... Adjust this accordingl,y if you implement this algorithm with greater CPU clock digit precision precision...

--2. Random Hashes Variables
Declare @Hash_Seed_Terran Bigint
Set @Hash_Seed_Terran = 17 --1 >= x <= 100,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Terran Hash Seed value must be different from the Vulcan and Andorian Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Seed_Vulcan Bigint
Set @Hash_Seed_Vulcan = 4000 --1 >= x <= 100,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Vulcan Hash Seed value must be different from Terran and Andorian Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Seed_Andorian Bigint
Set @Hash_Seed_Andorian = 831228 --1 >= x <= 100,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Andorian Hash Seed value must be different from Terran and Vulcan Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Shift Bigint
Set @Hash_Shift = 6 --1 >= x <= 10 ... Lower hash shift values will produce more randomicit integer hashes at smaller hash lengths; whereas, larger hash shift values will lead to more randomicit consecutive repetitions of integer hashes at larger hash lengths... This mechanism is a trade-off... If you are unsure which value to use, simply set the value to 1 for default behaviour which is more similar to exisiting class-probability-balanced random number generators... Nota Bene: The higher the Hash Seeds, the more likely it is that you will want a higher Hash Shift value... My advice, is experiment a little!... Disclaimer: I'm not even entirely sure if this variable control is really all that useful outside of theory, and haven't been able to test it in an applied manner, to my usual satisfaction and significance criteria... One more thing on this variable... It could even be repurposed as a hash span, instead of a hash shift, and would therefore allow for more efficient computation of hash values... It's up to you!!!...

Declare @Hash_Value_Length Bigint
Set @Hash_Value_Length = 40 --1 >= x < 1,000,000 (That's one million)... Any longer, and I fear that you may be up to something quite dangerous to the strategic goals of Starfleet!!!

Declare @Hash_Array_Length Bigint
Set @Hash_Array_Length = 1000 --1 >= x < As big as y're rig can handle... But, saying that, there is actually a precision limit which would eventually gradually nugify your Hash IDs at some point, as you increase Hash Array Length... The greater the data type precision they release for SQL Server, the greater this variable value can be... For now, I would not recommend any value above 1,000,000 (That's one million... Although this is probably unnecessarily conservative)...

Declare @Temporal_Distortion_Boolean Tinyint
Set @Temporal_Distortion_Boolean = 1 --PLEASE BE AWARE: You shouldn't use the temporal distortion feature here, if you require repeatability as a property of your outputs... If repeatanbility is required, then set this variable to zero (0)... Otherwise to one (1) in order to engage temproal distortion...

Declare @Temporal_Distortion_Flange As Tinyint
Set @Temporal_Distortion_Flange = 33 --Standard protocol flange would be around 50%, with recommended range from 33% to 66%, and limits at 0% and 100%... This basically controls how much Hash Seed values get temporally distorted...

Declare @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count As Bigint
Set @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count = 0 --Please keep this variable value assignation STRICTLY to the lowest acceptable value (zero {0} being the lowest allowed i_e_ no additional randomicity dilation), within the knowledge that the higher this value, the greater the algorithmic complexity, but at the same time, the less compute speed efficient the algorithm execution will be, especially at values above say 100 (not a theoretical limit though)...

--3. Random Numbers Variables
Declare @Range_Bounded_Number_Generation_Boolean Tinyint
Set @Range_Bounded_Number_Generation_Boolean = 0 --This variable can be set to either zero (0) --> random hash IDs will be generated... Or, it can be set to one (1) --> random integer numbers will be generated, according to the range bounds set on the @Obsidian_Range_Bounds global table variable below...
--Automatic override of the @Hash_Value_Length global variable from above...
If @Range_Bounded_Number_Generation_Boolean = 1
	Begin
		Set @Hash_Value_Length = 8 --You can only currently generate random numbers on a scale from zero to around nine pentillion (0 to 9,223,372,036,854,775,807) {limited only really by the Bigint data type max value...
	End

--Please note, that boundary values here below must be between around negative nine pentillion (-9,223,372,036,854,775,807) and around positive nine pentillion (9,223,372,036,854,775,807) inclusive... Also, even if range bounds are duplicate or overlapping, this will be carefully handled later on, so don't worry too much about this aspect!!!... Like I have said here, this algorithm can also handle negative integer range bounds, but just make sure that you have the bound values in the right order (The [Lower_Bound] column {most negative of the pair of bound values --> furthest from zero in the negative scale} and then the [Upper_Bound] column {least negative of the pair of bound values --> furthest from zero in the positive scale})
--Frequencies are comparative, and so normalise against eachother onto a 100% probability scale... As such, this column can hold either whole numbers (with their decimals all set to zero), or fractional numbers... It's up to you... If you simply want to use a standard frequency for certain rows, the @Default_Frequency_Value variable can be used, as demonstrated... To get vanilla default behaviour ie_ no frequency skewing of the classes, then you have three options... Either: 1. Set the @Range_Bound_Frequency_Boolean variable value to zero (0)... or... 2. Set all frequencies to the same value (Ideally the number one {1})... or... 3. Set all frequencies to the @Default_Frequency_Value variable...
Declare @Range_Bound_Frequency_Boolean As Tinyint
Set @Range_Bound_Frequency_Boolean = 0 --Can turn frequency distribution adjustment off, by assigning a value of zero (0)... Or on, by assigning a value of one (1)...

Declare @Default_Frequency_Value As Decimal(38, 19) --We restrict the [Frequency] value onto a 0,000,000,000,000,000,000.000000 digit-scale... Please make sure that you normalise your [Frequency] values in the table @Obsidian_Range_Bounds (along with the variable @Default_Frequency_Value), so that they are all positive values that are less than or equal to 9,223,372,036,854,775,807... and no zero only values please, otherwise they will not receive any manifestation...
Set @Default_Frequency_Value = 100.00 --Don't adjust this value (don't change it to something other than one hundred percent (100.00)), unless you know what you're doing!!!... You don't even need to use this variable at all, unless you are an advanced user...

Declare @Obsidian_Range_Bounds Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19)) --We restrict the [Frequency] value onto a 0,000,000,000,000,000,000.000000 digit-scale... Please make sure that you normalise your [Frequency] values in the table @Obsidian_Range_Bounds (along with the variable @Default_Frequency_Value), so that they are all positive values that are less than or equal to 9,223,372,036,854,775,807... and no zero only values please, otherwise they will not receive any manifestation...
Insert Into @Obsidian_Range_Bounds ([Lower_Bound], [Upper_Bound], [Frequency])
--I'm advising users to set the lower and upper bounds to the same value, only if you want to configure a bound for a single integer value instead of a contiguous range of values... Should have been obvious, but I know that under high stress and time pressures, that from experience, software operators lose insight with regards to trivial things like this!
Values
(-2, 0, @Default_Frequency_Value),
(0, 2, @Default_Frequency_Value),
(-500, -496, 200),
(1000000, 1000004, 100),
(30000, 30004, 300)


--(Partial data validation)
If (Select Max((Case When B.[Frequency] != A.[Frequency] Then 1 Else 0 End)) As [Corrupt_Frequency_Boolean] From @Obsidian_Range_Bounds A Inner Join @Obsidian_Range_Bounds B On (B.[Lower_Bound] >= A.[Lower_Bound] And B.[Lower_Bound] <= A.[Upper_Bound] Or B.[Upper_Bound] >= A.[Lower_Bound] And B.[Upper_Bound] <= A.[Upper_Bound])) = 1
	Begin
		Select 'EXCEPTION: Execution ended early, because your range bound frequencies, in the @Obsidian_Range_Bounds table, are corrupt... There is at least one case where overlapping range bounds have been assigned different frequencies!!!... Please amend appropriately, by either consolidating your range bounds, or by making sure that overlapping range bounds are assigned the same frequency value...'
		Return
	End


--(PART A: HASH EXECUTION)
--The following If statement helps to avoid unnecessary compute...
If @Temporal_Distortion_Boolean != 0
	Begin

		--Temporal Distortion Priming
		--When a hash seed is low, ie below 50 Million, then you probably would want a positive temporal distortion, for obvious reasons... But, when hash seed is high howver, i.e. above 50 Million, then you probably would benefit more from setting a corresponding negative temporal distortion, if any at all in either case...
		--(Terran)
		Declare @Temporal_Distortion_Toolean_Terran Int
		If @Hash_Seed_Terran <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Terran = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Terran > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Terran = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		--(Vulcan)
		Declare @Temporal_Distortion_Toolean_Vulcan Int
		If @Hash_Seed_Vulcan <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Vulcan = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Vulcan > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Vulcan = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		--(Andorian)
		Declare @Temporal_Distortion_Toolean_Andorian Int
		If @Hash_Seed_Andorian <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Andorian = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Andorian > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Andorian = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...


		--Temporal_Distortion
		Declare @System_Utc_Datetime As Varchar(Max)
		Set @System_Utc_Datetime = Cast(Sysutcdatetime() As Varchar(Max))

		Declare @Current_System_State_Clock_Index_Partition As Varchar(19)
		Set @Current_System_State_Clock_Index_Partition = (Substring(@System_Utc_Datetime, 16, 1) + Right(Replace(Replace(Replace(Replace(@System_Utc_Datetime, '-', ''), ' ', ''), ':', ''), '.', ''), @Core_Algorithmic_CPU_Clock_Digit_Precision)) --I have partially 'reverse sliced' the granularity here (the 'full reversing' takes place later on in the algorithm), because for my database, the year comes first in this value, and the greatest precision seconds decimal comes last... Whereas, you always want the least granularity last (the year segment), and the greatest granularity first (the highest precision sub-second)... If you do not properly handle this dynamic (which arises due to different datetime2 formats across different databases, when calling the Sysutcdatetime() function), then your temporal distortion will be less than ideal, and possibly pointless, in terms of maximising cyber security protections... Nota Bene: In this current implementation, we are only using part of the Sysutcdatetime() function Datetime2 output value (This will need to be amended in cases where greater Hash Seed data type precisions are enabled in SQL Server)... Coming back to this at a later date, I have realised that we can infact make full use of the more precise (second) minute digit in the system datetime, as this does indeed cycle around all numbers zero through nine in an unbiased/balanced fashion... THIS IS VERY HANDY LATER ON, IN ORDER TO FIX THE INDEX GAP FUDGE, WHICH PREVIOUSLY AROSE (BUT HAS NOW BEEN FIXED) DUE TO NOT HAVING ENOUGH USEABLE CPU CLOCK DIGITS TO APPROPRIATELY INTERACT WITH SEED INDEXES!!!
		--This temporal dilator technique must use fractional numbers up to and including the first seconds digit (from greatest decimal precision digit up to single digit seconds, which in this case provides 8 consecutive digits), but no more than this, such as also using hours or days etc_, because otherwise the temproal distortion would be biased and potentially easier to cyber hack (hours for example, don't cover all numbers between zero and ninety nine... they only cover twenty three at most, which means the distribution of outputs would be skewed to lower numbers {Especially in the less precise hour digit}...)...
		
		--We use a zero injection technique later on in the algorith (in the clock index rebuild), in order to boost the dynamic nature of the temporal randomicit distortion... Otherwise, most distortions would either be very close or very far from the original Hash Seed values...
		Declare @Normalised_Zero_Injection_Count As Tinyint
		Set @Normalised_Zero_Injection_Count = Round((((Cast(Substring(@Current_System_State_Clock_Index_Partition, (@Core_Algorithmic_CPU_Clock_Digit_Precision + 1), 1) As Decimal(38, 37)) / Cast(10 As Decimal(38, 36))) * (Cast(@Core_Algorithmic_CPU_Clock_Digit_Precision As Decimal(38, 37)) + 1)) * (Cast((100 - @Temporal_Distortion_Flange) As Decimal(38, 35)) / Cast(100 As Decimal(38, 35)))), 0) --We use the greatest precision limit integer to decide how many zeroes we are injecting into the clock index (so that we can later fully utilise the full Hash Seed range when temporally distorting)... Otherwise, only very small temporal perturbations would occur (due to most numbers in the Hash Seed range being in the tens of millions), which would significantly reduce the cyber defensive power of this temporal distortion technique... The range from zero to nine (0 to 9), has been balanced out, by dividing with a value of 10 {called proportional or output normalisation}... Please also note, the alteration from the typical Decimal(38, 37) {which would have worked with an upper range limit of nine (9)}, but because we now have an upper range limit of ten (10), we need to use the {Decimal(38, 36)} data type here, in order to avoid arithmetic overflows or something like that, where the number can't be stored as it is larger than the variable data type)... We normalise onto a scale from one to eight (depending on degree of available datetime2 fractional precision), for obvious reasons (divide zero errors and misaligned ranges {we currently only want nine digits in our distortion capability (with no possibility of producing an overall zero), whereas eights and nines could appear some times, unless we normalise them out})... We also implement the tmeporal distortion flange technique here, in order to reduce the degree of zero injection according to the degree of flange (This will give our output Hash Seeds more dynamicism, because they can be promoted to change more {At higher flanges}, depending on the same inputs)...
		
		--Manual transformation step I know, but its only 8 values right now, given the size of the Hash Seed ranges... Speak to a Catholic priest if this shortcut upsets you...
		Declare @Temporal_Distortion_Index Table ([Order] Tinyint, [Clock_Index] Tinyint)

		--Rebuild of the clock index
		Declare @Loop_Count_0001 As Bigint
		Set @Loop_Count_0001 = 0
		--This following loop basically injects the zeroes...
		While @Loop_Count_0001 < @Core_Algorithmic_CPU_Clock_Digit_Precision --Nine is currently the 'reverse sliced' clock index length...
			Begin
		
				Set @Loop_Count_0001 = (@Loop_Count_0001 + 1)
				
				--Here in the sourcecode, in the conditional if statement below, that rebuilds the clock index... The last clock index integer is used in order to determine how many zeroes are injected...
				If @Loop_Count_0001 < @Normalised_Zero_Injection_Count
					Begin
						Insert Into @Temporal_Distortion_Index ([Order], [Clock_Index])
						Values (Cast(@Loop_Count_0001 As Tinyint), Cast(0 As Tinyint))
					End
				Else If @Loop_Count_0001 >= @Normalised_Zero_Injection_Count
					Begin
						Insert Into @Temporal_Distortion_Index ([Order], [Clock_Index])
						Values (Cast(@Loop_Count_0001 As Tinyint), Cast(Substring(@Current_System_State_Clock_Index_Partition, (@Core_Algorithmic_CPU_Clock_Digit_Precision - (@Loop_Count_0001 - 1)), 1) As Tinyint)) --(@Core_Algorithmic_CPU_Clock_Digit_Precision - @Loop_Count_0001) because you want to always use the most dynamic and frequently changing digit integers first, after leaving out the greatest precision digit integer in position nine, which was used to generate a number of zeros injection value previously...
					End
			End
		
		--This codeblock fully rebuilds...
		Declare @Current_System_State_Clock_Index_Partition_Rebuilt As Varchar(19)
		Set @Current_System_State_Clock_Index_Partition_Rebuilt = Cast((Select String_Agg(Cast([Clock_Index] As Varchar(19)), '') Within Group (Order By [Order] Asc) As [Zero_Injected_Clock_Index] From @Temporal_Distortion_Index) As Varchar(19))
		
		--We can now distort our hash seeds appropriately, as follows...
		Declare @Temporal_Distortion_Granularity_Step_Size As Decimal(38, 29)
		Set @Temporal_Distortion_Granularity_Step_Size = (Cast(@Current_System_State_Clock_Index_Partition_Rebuilt As Decimal(38, 30)) / Cast((@Core_Algorithmic_Decimal_Data_Type_Precision - 1) As Decimal(38, 30))) --Please make sure that this 100 million value remains in synchronisation with the rest of the algorithm, if amending in any significant way (for example greater precision data types and therefore larger seed ranges)... Also make sure it is in synchronisation with the seed range limit data validation constraints (Which I haven't actually implemented here, but simply mentioned in the comments above)...

		--1. Terran Temporal Distortion
		If @Temporal_Distortion_Toolean_Terran = -1
			Begin
				Set @Hash_Seed_Terran = Floor((@Hash_Seed_Terran - ((@Hash_Seed_Terran - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Terran = 1
			Begin
				Set @Hash_Seed_Terran = Ceiling((@Hash_Seed_Terran + ((@Core_Algorithmic_Decimal_Data_Type_Precision - @Hash_Seed_Terran) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End
		--2. Vulcan Temporal Distortion
		If @Temporal_Distortion_Toolean_Vulcan = -1
			Begin
				Set @Hash_Seed_Vulcan = Floor((@Hash_Seed_Vulcan - ((@Hash_Seed_Vulcan - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Vulcan = 1
			Begin
				Set @Hash_Seed_Vulcan = Ceiling((@Hash_Seed_Vulcan + ((@Core_Algorithmic_Decimal_Data_Type_Precision - @Hash_Seed_Vulcan) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End
		--3. Andorian Temporal Distortion
		If @Temporal_Distortion_Toolean_Andorian = -1
			Begin
				Set @Hash_Seed_Andorian = Floor((@Hash_Seed_Andorian - ((@Hash_Seed_Andorian - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Andorian = 1
			Begin
				Set @Hash_Seed_Andorian = Ceiling((@Hash_Seed_Andorian + ((@Core_Algorithmic_Decimal_Data_Type_Precision - @Hash_Seed_Andorian) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End

		--Please note, that here below, I have set different temproal distortion modifiers for the three different Hash Seed distortions... This is highly advisable, given that the algorithm is not designed to work when any of the three Hash Seeds are identical!!!
		--Limit Modifier
		--(We here need to worry about modifying on the hash seed range limits, because it is assumed that a temporal distortion could cause all three hash seeds to clash onto either 1 or 100,000,000...)
		If @Hash_Seed_Terran = 1
			Begin
				If @Hash_Seed_Vulcan = 1
					Begin
						If @Hash_Seed_Andorian = 1
							Begin
								Set @Hash_Seed_Terran = 1
								Set @Hash_Seed_Vulcan = 2
								Set @Hash_Seed_Andorian = 3
							End
					End
			End
		Else If @Hash_Seed_Terran = @Core_Algorithmic_Decimal_Data_Type_Precision
			Begin
				If @Hash_Seed_Vulcan = @Core_Algorithmic_Decimal_Data_Type_Precision
					Begin
						If @Hash_Seed_Andorian = @Core_Algorithmic_Decimal_Data_Type_Precision
							Begin
								Set @Hash_Seed_Terran = (@Core_Algorithmic_Decimal_Data_Type_Precision - 2)
								Set @Hash_Seed_Vulcan = (@Core_Algorithmic_Decimal_Data_Type_Precision - 1)
								Set @Hash_Seed_Andorian = @Core_Algorithmic_Decimal_Data_Type_Precision
							End
					End
			End
		--Proximal Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Andorian = @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
			End
		--Distal Terran Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Andorian > @Hash_Seed_Terran
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
					End
				Else If @Hash_Seed_Andorian < @Hash_Seed_Terran
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran + 1)
					End
			End
		--Distal Andorian Modifier
		Else If @Hash_Seed_Andorian = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Terran > @Hash_Seed_Andorian
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian - 1)
					End
				Else If @Hash_Seed_Terran < @Hash_Seed_Andorian
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
			End
		--Inverted Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Andorian
			Begin
				If @Hash_Seed_Terran > @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
				Else If @Hash_Seed_Andorian < @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
					End
			End

	End


--Hash_Value_Scaffold
Declare @Dynamic_SQL_Data_Intermediate_Variable_Hash_Value As Nvarchar(Max)
Set @Dynamic_SQL_Data_Intermediate_Variable_Hash_Value =
(
'Declare @Number_Seeds Table ([Number_Seed] NvarChar(1))
Insert Into @Number_Seeds ([Number_Seed])
Values (''0''), (''1''), (''2''), (''3''), (''4''), (''5''), (''6''), (''7''), (''8''), (''9'') ' +
Replace(dbo.Obsidian_Element_Index_Generator_Code_Parallel_Super_Fast(@Hash_Value_Length), '@Index_Count', @Hash_Value_Length) --This algorithm can be found on my GitHub account in the same repository that you found this script in.
)

Declare @Obsidian_Index_Scaffold_Hash_Value Table ([Index] Int)
Insert Into @Obsidian_Index_Scaffold_Hash_Value ([Index])
Execute (@Dynamic_SQL_Data_Intermediate_Variable_Hash_Value)


--Hash_Array_Scaffold
Declare @Dynamic_SQL_Data_Intermediate_Variable_Hash_Array As Nvarchar(Max)
Set @Dynamic_SQL_Data_Intermediate_Variable_Hash_Array =
(
'Declare @Number_Seeds Table ([Number_Seed] NvarChar(1))
Insert Into @Number_Seeds ([Number_Seed])
Values (''0''), (''1''), (''2''), (''3''), (''4''), (''5''), (''6''), (''7''), (''8''), (''9'') ' +
Replace(dbo.Obsidian_Element_Index_Generator_Code_Parallel_Super_Fast(@Hash_Array_Length), '@Index_Count', @Hash_Array_Length) --This algorithm can be found on my GitHub account in the same repository that you found this script in.
)

Declare @Obsidian_Index_Scaffold_Hash_Array Table ([Index] Int)
Insert Into @Obsidian_Index_Scaffold_Hash_Array ([Index])
Execute (@Dynamic_SQL_Data_Intermediate_Variable_Hash_Array)


--Hash_Generation
Declare @Pillars_Of_Starfleet_A Table ([Array_Index] Bigint, [Value_Index] Bigint, [Scrambled_Eggs_Benedict] Decimal(38, 37), [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37))
Insert Into @Pillars_Of_Starfleet_A ([Array_Index], [Value_Index], [Scrambled_Eggs_Benedict], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
Select
	A.[Index] As [Array_Index],
	B.[Index] As [Value_Index],
	(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 1)) As [Scrambled_Eggs_Benedict], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Terrans appreciate scrambled eggs for brunch (It is used mainly as a hangover cure, along with a bloody mary, after the exploits of a night 'out on the town'... Plus, a 'famous prophet' of the never ending millenium, has declared that Canadians will probably be all the rage, in some significant manner, during the first space age race!!!)... It's been reversed, as a warning to the 21st century youth, that booze binges lead to beer belly battlegrounds, where your stomach fights for survival, and may not actually be able to hold down a meal...
	(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 1)) As [A_Tiny_Mush_Of_Vulcan_Flan], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Vulcans don't really appreciate flan (It is used mainly as a penance during the rigours of Kolinahr!!!)...
	(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 1)) As [A_Huge_Slice_Of_Andorian_Pie] -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Andorians really appreciate pie (It is usually their main course in a meal!!!)...
From @Obsidian_Index_Scaffold_Hash_Array A
Cross Join @Obsidian_Index_Scaffold_Hash_Value B

Declare @Pillars_Of_Starfleet_B Table ([Array_Index] Bigint, [Value_Index] Bigint, [Scrambled_Eggs_Benedict] Varchar(Max), [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37))
Insert Into @Pillars_Of_Starfleet_B ([Array_Index], [Value_Index], [Scrambled_Eggs_Benedict], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
Select
	[Array_Index] As [Array_Index],
	[Value_Index] As [Value_Index],
	Reverse(Cast(([Scrambled_Eggs_Benedict] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 6))) As Varchar(Max))) As [Scrambled_Eggs_Benedict], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Terrans appreciate scrambled eggs for brunch (It is used mainly as a hangover cure, along with a bloody mary, after the exploits of a night 'out on the town'... Plus, a 'famous prophet' of the never ending millenium, has declared that Canadians will probably be all the rage, in some significant manner, during the first space age race!!!)... It's been reversed, as a warning to the 21st century youth, that booze binges lead to beer belly battlegrounds, where your stomach fights for survival, and may not actually be able to hold down a meal...
	([A_Tiny_Mush_Of_Vulcan_Flan] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 6))) As [A_Tiny_Mush_Of_Vulcan_Flan], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Vulcans don't really appreciate flan (It is used mainly as a penance during the rigours of Kolinahr!!!)...
	([A_Huge_Slice_Of_Andorian_Pie] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 6))) As [A_Huge_Slice_Of_Andorian_Pie] -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Andorians really appreciate pie (It is usually their main course in a meal!!!)...
From @Pillars_Of_Starfleet_A


If @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count > 0
	Begin
		
		--Hash_Dilator_Scaffold
		Declare @Dynamic_SQL_Data_Intermediate_Variable_Hash_Dilator As Nvarchar(Max)
		Set @Dynamic_SQL_Data_Intermediate_Variable_Hash_Dilator =
		(
		'Declare @Number_Seeds Table ([Number_Seed] NvarChar(1))
		Insert Into @Number_Seeds ([Number_Seed])
		Values (''0''), (''1''), (''2''), (''3''), (''4''), (''5''), (''6''), (''7''), (''8''), (''9'') ' +
		Replace(dbo.Obsidian_Element_Index_Generator_Code_Parallel_Super_Fast(@Pseudo_Infinite_Dimensional_Complexity_Dilator_Count), '@Index_Count', @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count) --This algorithm can be found on my GitHub account in the same repository that you found this script in.
		)

		Declare @Obsidian_Index_Scaffold_Hash_Dilator_Intermediate Table ([Index] Int)
		Insert Into @Obsidian_Index_Scaffold_Hash_Dilator_Intermediate ([Index])
		Execute (@Dynamic_SQL_Data_Intermediate_Variable_Hash_Dilator)

		--We also need to activate opportunistic buffers for the dilator array in the warp drive, in order to minimise the probability of plasma contamination incidents...
		Declare @Obsidian_Index_Scaffold_Hash_Dilator_Buffered Table ([Index] Int)
		Insert Into @Obsidian_Index_Scaffold_Hash_Dilator_Buffered ([Index])
		Select
			([Index] + @Hash_Array_Length) As [Index] --Warp coil offsetting occurs here...
		From @Obsidian_Index_Scaffold_Hash_Dilator_Intermediate

		
		--Dilator_Generation
		Declare @Dilators_A Table ([Array_Index] Bigint, [Value_Index] Bigint, [Scrambled_Eggs_Benedict] Decimal(38, 37), [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37))
		Insert Into @Dilators_A ([Array_Index], [Value_Index], [Scrambled_Eggs_Benedict], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
		Select
			A.[Index] As [Array_Index],
			B.[Index] As [Value_Index],
			(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 1)) As [Scrambled_Eggs_Benedict], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Terrans appreciate scrambled eggs for brunch (It is used mainly as a hangover cure, along with a bloody mary, after the exploits of a night 'out on the town'... Plus, a 'famous prophet' of the never ending millenium, has declared that Canadians will probably be all the rage, in some significant manner, during the first space age race!!!)... It's been reversed, as a warning to the 21st century youth, that booze binges lead to beer belly battlegrounds, where your stomach fights for survival, and may not actually be able to hold down a meal...
			(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 1)) As [A_Tiny_Mush_Of_Vulcan_Flan], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Vulcans don't really appreciate flan (It is used mainly as a penance during the rigours of Kolinahr!!!)...
			(Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 1)) As [A_Huge_Slice_Of_Andorian_Pie] -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Andorians really appreciate pie (It is usually their main course in a meal!!!)...
		From @Obsidian_Index_Scaffold_Hash_Dilator_Buffered A
		Cross Join @Obsidian_Index_Scaffold_Hash_Value B

		Declare @Dilators_B Table ([Value_Index] Bigint, [Scrambled_Eggs_Benedict] Decimal(38, 37), [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37))
		Insert Into @Dilators_B ([Value_Index], [Scrambled_Eggs_Benedict], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
		Select
			[Value_Index] As [Value_Index],
			([Scrambled_Eggs_Benedict] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Terran - 1))) + 6))) As [Scrambled_Eggs_Benedict], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Terrans appreciate scrambled eggs for brunch (It is used mainly as a hangover cure, along with a bloody mary, after the exploits of a night 'out on the town'... Plus, a 'famous prophet' of the never ending millenium, has declared that Canadians will probably be all the rage, in some significant manner, during the first space age race!!!)... It's been reversed, as a warning to the 21st century youth, that booze binges lead to beer belly battlegrounds, where your stomach fights for survival, and may not actually be able to hold down a meal...
			([A_Tiny_Mush_Of_Vulcan_Flan] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Vulcan - 1))) + 6))) As [A_Tiny_Mush_Of_Vulcan_Flan], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Vulcans don't really appreciate flan (It is used mainly as a penance during the rigours of Kolinahr!!!)...
			([A_Huge_Slice_Of_Andorian_Pie] + (Cast(2 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 4)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 5)) + (Cast(1 As Decimal(38, 37)) / ((8 * (((([Array_Index] - 1) * @Hash_Value_Length) + [Value_Index]) + (@Hash_Seed_Andorian - 1))) + 6))) As [A_Huge_Slice_Of_Andorian_Pie] -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Andorians really appreciate pie (It is usually their main course in a meal!!!)...
		From @Dilators_A

		--We use three dilation repeaters, in order to ensure that we never lose engine viability, due to low-precision-induced conk-out...
		--I suppose the question is, why has Starfleet decreed that for the forseeable future, due to unforseen circumstances, all military rations must be cooked using a warp engine... Seems like overkill maybe... dunno...

		--Dilation_Servings
		Declare @Dilation_Servings_Intermediate Table ([Order] Bigint, [Value_Index] Bigint, [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37));
		Insert Into @Dilation_Servings_Intermediate ([Order], [Value_Index], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
		Select
			Row_Number() Over(Order By [Scrambled_Eggs_Benedict] Asc) As [Order], --Need to order by scrambled column in order to ensure some form of deterministic algorithmic repeatability when using dilator features...
			[Value_Index] As [Value_Index],
			[A_Tiny_Mush_Of_Vulcan_Flan] As [A_Tiny_Mush_Of_Vulcan_Flan],
			[A_Huge_Slice_Of_Andorian_Pie] As [A_Huge_Slice_Of_Andorian_Pie]
		From @Dilators_B

	End


--Hash_Servings
Declare @Hash_Servings_Final Table ([Order] Bigint, [Firmament_Feast] Varchar(Max))
If @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count = 0
	Begin
		Insert Into @Hash_Servings_Final ([Order], [Firmament_Feast])
		Select
			[Array_Index] As [Order],
			String_Agg(Cast(Sqrt(Square(Cast(Substring(Reverse(Cast(([A_Tiny_Mush_Of_Vulcan_Flan] + [A_Huge_Slice_Of_Andorian_Pie]) As Varchar(Max))), (Case When ([Value_Index] % @Hash_Shift) = 0 Then @Hash_Shift Else ([Value_Index] % @Hash_Shift) End), 1) As Tinyint))) As Varchar(Max)), '') Within Group (Order By [Scrambled_Eggs_Benedict] Asc)  As [Firmament_Feast] --We can now serve a tasty pseudo-random integer meal... Please be aware that there is currently no particular order in which the courses and their constituents are brought together (which is one of the main strengths of the algorithm... of course... excuse the pun...)... As such, there may be some usecases or circumstances where this is unacceptable (Starfleet Standard Issue Blitz Rations don't exactly make the mouth water, eh???)... Here, we also use an index modulo shift technique, in order to increase the randomicit features and behaviours of the algorithm (It activates the Hash Shift control)... The core 'flan' minus 'pie' method here, basically dilates the combinatorial search space by the power of 10, such that you now have a double nested exponent on the overall complexity of the algorithm!!!... Just as a side, but the spatial dialtion implemented here, by using the two pillar dimensions, could possibly be used as part of a model of the extreme dimensional characteristics of a black hole (In essence, there is theoretically no limit to the amount of spatial dilation that one could model)... This dilation technique has now been implemented, and is controlled by a global variable...
		From @Pillars_Of_Starfleet_B
		Group By [Array_Index]
	End
Else If @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count > 0
	Begin
		Insert Into @Hash_Servings_Final ([Order], [Firmament_Feast])
		Select
			A.[Array_Index] As [Order],
			String_Agg(Cast(Sqrt(Square(Cast(Substring(Reverse(Cast((A.[A_Tiny_Mush_Of_Vulcan_Flan] + A.[A_Huge_Slice_Of_Andorian_Pie] + B.[A_Tiny_Mush_Of_Vulcan_Flan] + B.[A_Huge_Slice_Of_Andorian_Pie]) As Varchar(Max))), (Case When (A.[Value_Index] % @Hash_Shift) = 0 Then @Hash_Shift Else (A.[Value_Index] % @Hash_Shift) End), 1) As Tinyint))) As Varchar(Max)), '') Within Group (Order By A.[Scrambled_Eggs_Benedict] Asc)  As [Firmament_Feast] --We can now serve a tasty pseudo-random integer meal... Please be aware that there is currently no particular order in which the courses and their constituents are brought together (which is one of the main strengths of the algorithm... of course... excuse the pun...)... As such, there may be some usecases or circumstances where this is unacceptable (Starfleet Standard Issue Blitz Rations don't exactly make the mouth water, eh???)... Here, we also use an index modulo shift technique, in order to increase the randomicit features and behaviours of the algorithm (It activates the Hash Shift control)... The core 'flan' minus 'pie' method here, basically dilates the combinatorial search space by the power of 10, such that you now have a double nested exponent on the overall complexity of the algorithm!!!... Just as a side, but the spatial dialtion implemented here, by using the two pillar dimensions, could possibly be used as part of a model of the extreme dimensional characteristics of a black hole (In essence, there is theoretically no limit to the amount of spatial dilation that one could model)... This dilation technique has now been implemented, and is controlled by a global variable...
		From @Pillars_Of_Starfleet_B A
		Inner Join @Dilation_Servings_Intermediate B On
			((B.[Order] % @Pseudo_Infinite_Dimensional_Complexity_Dilator_Count) = 0 And B.[Value_Index] = A.[Value_Index])
		Group By A.[Array_Index]
	End


--And so the three insatiable Starfleet God's of Gluttony are born into the cosmos: 1. Haon the Father of the Terrans; 2. Divad the brother of the Vulcans; and 3. Susej the friend of the Andorians...


--(PART B: NUMBER EXECUTION)
If @Range_Bounded_Number_Generation_Boolean = 1
	Begin
		
		Declare @Obsidian_Range_Bounds_Normalised Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		--Below, we normalise the digit range bounds onto a 100% [Frequency] scale, or we set all frequencies to 1.000000 (depending on the appropriate global variable, which activates distributive random sampling)...
		If @Range_Bound_Frequency_Boolean = 0
			Begin
				
				Insert Into @Obsidian_Range_Bounds_Normalised ([Lower_Bound], [Upper_Bound], [Frequency])
				Select
					[Lower_Bound] As [Lower_Bound],
					[Upper_Bound] As [Upper_Bound],
					1 As [Frequency] --Setting this value to one (1) across all rows, forces equal/balanced class distribution...
				From @Obsidian_Range_Bounds
			
			End
		Else If @Range_Bound_Frequency_Boolean = 1
			Begin

				Declare @Obsidian_Range_Bounds_Maximum_Frequency As Decimal(38, 19)
				Set @Obsidian_Range_Bounds_Maximum_Frequency = (Select Max([Frequency]) From @Obsidian_Range_Bounds)

				Insert Into @Obsidian_Range_Bounds_Normalised ([Lower_Bound], [Upper_Bound], [Frequency])
				Select
					[Lower_Bound] As [Lower_Bound],
					[Upper_Bound] As [Upper_Bound],
					Cast(([Frequency] / @Obsidian_Range_Bounds_Maximum_Frequency) As Decimal(38, 19)) As [Frequency]
				From @Obsidian_Range_Bounds
			
			End
		
		--We remove all duplicate bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency]  Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct ([Lower_Bound], [Upper_Bound], [Frequency])
		Select Distinct
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Range_Bounds_Normalised

		--We anchor the bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Row_Number() Over(Order By (Select Null)) As [Anchor_Order], --I have used a null returning subquery within the ordering clause, as this seems to optimise for greatest speed... I think the SQL Server engine simply ignores the ordering clause in this case, which is the exact behaviour we want.
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct

		--We remove all subsidiary bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			A.[Anchor_Order] As [Anchor_Order],
			A.[Lower_Bound] As [Lower_Bound], 
			A.[Upper_Bound] As [Upper_Bound],
			A.[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored A
		Left Join @Obsidian_Bounds_Distinct_Anchored B
			On (
				B.[Anchor_Order] <> A.[Anchor_Order]
				And B.[Lower_Bound] <= A.[Lower_Bound]
				And B.[Upper_Bound] >= A.[Upper_Bound]
			)
		Where 
			B.[Lower_Bound] Is Null
			And B.[Upper_Bound] Is Null
	
		--We find the middle of chain overlapping bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Min(A.[Anchor_Order]) As [Anchor_Order],
			Min(B.[Lower_Bound]) As [Lower_Bound], 
			Max(B.[Upper_Bound]) As [Upper_Bound],
			Max(B.[Frequency]) As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds A
		Cross Join @Obsidian_Bounds_Distinct_Anchored_Superbounds B
		Where
			B.[Lower_Bound] >= A.[Lower_Bound]
			And B.[Lower_Bound] <= A.[Upper_Bound]
			Or
			B.[Upper_Bound] >= A.[Lower_Bound]
			And B.[Upper_Bound] <= A.[Upper_Bound]
		Group By A.[Anchor_Order]

		--We find the ends of chain overlapping bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Min(A.[Anchor_Order]) As [Anchor_Order],
			Min(B.[Lower_Bound]) As [Lower_Bound], 
			Max(B.[Upper_Bound]) As [Upper_Bound],
			Max(B.[Frequency]) As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle A
		Cross Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle B
		Where
			B.[Lower_Bound] >= A.[Lower_Bound]
			And B.[Lower_Bound] <= A.[Upper_Bound]
			Or
			B.[Upper_Bound] >= A.[Lower_Bound]
			And B.[Upper_Bound] <= A.[Upper_Bound]
		Group By A.[Anchor_Order]

		--We find all distinct chain bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct ([Lower_Bound], [Upper_Bound], [Frequency])
		Select Distinct
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends

		--We anchor the final bounds in the codeblock below, for use later on in this query.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Row_Number() Over(Order By [Lower_Bound] Asc) As [Anchor_Order], --I have used a null returning subquery within the ordering clause, as this seems to optimise for greatest speed... I think the SQL Server engine simply ignores the ordering clause in this case, which is the exact behaviour we want.
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct
		
		--The following codeblock counts the unique integer classes within the digit bounds provided to the function. They handle digit boundary overlaps and chains appropriately.
		Declare @Unique_Integer_Class_Limit Bigint
		Set @Unique_Integer_Class_Limit = 
		(
		Select 
			(Case When @Range_Bound_Frequency_Boolean = 1 Then Round(Sum(((([Upper_Bound] - [Lower_Bound]) + 1) * ([Frequency] * 100))), 0) Else (Case When @Range_Bound_Frequency_Boolean = 0 Then Sum((([Upper_Bound] - [Lower_Bound]) + 1)) Else Null End) End)
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored
		)

		--Here, we accumulate unique integer class counts, by building a meta range boundary series...
		Declare @Unique_Integer_Class_Meta_Range_Boundary_Series Table ([Anchor_Order] Bigint, [Cumulative_Integer_Class_Count] Bigint)
		--We insert a prefixial row, in order to properly handle the lowest range boundary later on in the randomicity serving technique...
		Insert Into @Unique_Integer_Class_Meta_Range_Boundary_Series ([Anchor_Order], [Cumulative_Integer_Class_Count])
		Values
		(0, 0)
		--We then insert the rest of the actual range boundary ancillary data, which is also used later on in the randomicity serving technique...
		Insert Into @Unique_Integer_Class_Meta_Range_Boundary_Series ([Anchor_Order], [Cumulative_Integer_Class_Count])
		Select
			A.[Anchor_Order] As [Anchor_Order],
			(Case When @Range_Bound_Frequency_Boolean = 1 Then Round(Sum((((B.[Upper_Bound] - B.[Lower_Bound]) + 1) * (B.[Frequency] * 100))), 0) Else (Case When @Range_Bound_Frequency_Boolean = 0 Then Sum(((B.[Upper_Bound] - B.[Lower_Bound]) + 1)) Else Null End) End) As [Cumulative_Integer_Class_Count]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored A
		Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored B On
			(B.[Anchor_Order] <= A.[Anchor_Order])
		Group By A.[Anchor_Order]

	End

--Randomicity_Serving
Declare @Penultimate_Randomicity_Serving Table ([Order] Bigint, [Random_Meta_Range_Boundary_Index] Decimal(38, 19))
				

If @Range_Bounded_Number_Generation_Boolean = 0 --If you have set global variables to serve Random Integer Hash IDs
	Begin
		
		Select
			[Order] As [Order],
			[Firmament_Feast] As [Firmament_Feast]
		From @Hash_Servings_Final
		Order By [Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio... Please remove this line of code when you speed test...
	
	End
Else If @Range_Bounded_Number_Generation_Boolean = 1 --If you have set global variables to serve Random Numbers (As defined in the @Obsidian_Range_Bounds global table variable)
	Begin
		
		If @Range_Bound_Frequency_Boolean = 0
			Begin

				Insert Into @Penultimate_Randomicity_Serving ([Order], [Random_Meta_Range_Boundary_Index])
				Select
					[Order],
					Cast(('0.' + [Firmament_Feast]) As Decimal(38, 19)) As [Random_Meta_Range_Boundary_Index] --The overall index for the randomly selected number... This can then be used to map across all the ordered range boundaries from the global variable @Obsidian_Range_Bounds, and therefore return the correct random number...
				From @Hash_Servings_Final
				
				Select
					A.[Order],
					Ceiling(((E.[Lower_Bound] - 1) + ((A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit) - B.[Cumulative_Integer_Class_Count]))) As [Random_Numbers] --We use the Ceiling() function to correct rounding errors...
				From @Penultimate_Randomicity_Serving A
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series B On
					(B.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Left Join @Unique_Integer_Class_Meta_Range_Boundary_Series C On
					(C.[Anchor_Order] > B.[Anchor_Order] And C.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series D On
					(D.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored E On
					(E.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Where C.[Anchor_Order] Is Null
				Order By A.[Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio... Please remove this line of code when you speed test...

			End
		Else If @Range_Bound_Frequency_Boolean = 1
			Begin

				Insert Into @Penultimate_Randomicity_Serving ([Order], [Random_Meta_Range_Boundary_Index])
				Select
					[Order],
					Cast(('0.' + [Firmament_Feast]) As Decimal(38, 19)) As [Random_Meta_Range_Boundary_Index] --The overall index for the randomly selected number... This can then be used to map across all the ordered range boundaries from the global variable @Obsidian_Range_Bounds, and therefore return the correct random number...
				From @Hash_Servings_Final
				
				Declare @Consolidated_Bound_Count As Bigint
				Set @Consolidated_Bound_Count = (Select Count(1) From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored)

				Select
					A.[Order],
					Cast(Ceiling((Cast((E.[Lower_Bound] - 1) As Decimal(38, 19)) + ((((Cast(@Unique_Integer_Class_Limit As Decimal(38, 19)) * Cast(A.[Random_Meta_Range_Boundary_Index] As Decimal(38, 19))) - Cast(B.[Cumulative_Integer_Class_Count] As Decimal(38, 19))) / ((Cast(D.[Cumulative_Integer_Class_Count] As Decimal(38, 19)) - Cast(B.[Cumulative_Integer_Class_Count] As Decimal(38, 19))) + 1)) * Cast(((E.[Upper_Bound] - E.[Lower_Bound]) + 1) As Decimal(38, 19))))) As Bigint) As [Random_Numbers] --We cross-normalise interboundary distance, and apply this to the random index, in order to derive a [Lower_Bound] offset for each row... We use the Ceiling() functions in order to correct for rounding errors, which arise with high probability when mathematically operating on mixed data types of Bigints and Decimals... We also Cast( As Bigint), because of the ultimately unwanted injection of decimals from the [Random_Meta_Range_Boundary_Index] term...
				From @Penultimate_Randomicity_Serving A
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series B On
					(B.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Left Join @Unique_Integer_Class_Meta_Range_Boundary_Series C On
					(C.[Anchor_Order] > B.[Anchor_Order] And C.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series D On
					(D.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored E On
					(E.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Where C.[Anchor_Order] Is Null
				Order By A.[Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio... Please remove this line of code when you speed test...
			
			End
		
	End