--MS_Obsidian_Superfast_Starfleet_Pseudo_Quantum_Randomicity_Generator_v00.000.0075_MAJOR_RELEASE
--With this algorithm, you're generating integer string hashes, comprised of single digit integer numbers (0 to 9), where each digit is indexed from a scrambled and deconstructed number partition, with π (pi) itself providing the necessary decimal sequence predicate for the partitioning regime (which is itself an irrational, class-balanced, almost certainly 'fully' randomicit, number, with an infinite decimal precision limit {so long as you don't run out of atoms in the universe to store it with}... This gives the algorithm theoretically 'infinite virtual potential')... As a result, the combinatorial search space for each digit of a generated Starfleet Integer Hash ID, is linearly proportional to its character length, as follows:
--GENERAL COMBINATORIAL COMPLEXITY CALCULATION : (10 (single digit integer range) ^40 (typical digit hash length)) x 10^8 (Terran seed range {currently limited by the data type decimal precision in SQL Server}) x 10^8 (Vulcan seed range {currently limited by the data type decimal precision in SQL Server}) x 10^8 (Andorian seed range {currently limited by the data type decimal precision in SQL Server}) x 10^1 (maximum hash shift positions {currently limited by the data type decimal precision in SQL Server}) x 10^1 (space dilation {dimensional pillar delta}) x 10^1 (temporal distortion {system state clocking}) = 10^67... This is an extremely large number, much larger than a VI(R)GINTILLION in short-scale naming... In other words, insanely complex (and that's completely ignoring the fact that it is derived from a completely random foundation sequence)... No one is ever going to ever be able to cyber-hack this algorithm in any kind of reasonable (and I would say even significantly fictitious) reality, providing you don't do something really stupid with its application to your problem context...
--As you can probably tell by now therefore, ChatGPT thinks that this is a very random number generator indeed!!!... Please be aware though, that cyber security is only ensured, so long as @Hash_Seeds (All of Terran, Vulcan, and Andorian) are kept private (and to be honest, you probably want to keep all the assigned global variable values private, for the same reason!!!)...
--'Keep your eyes peeled' (Non-Andorians only of course... Wouldn't want to offend their Augur-Prime) for an additional temporal distortion technique (THIS IS NOW IMPLEMENTED IN THE ALGORITH!!!)... Used to be releasing anytime soon!!!... It will hopefully mean that even if somehow a cyber adversary obtained your @Hash_Seeds, the additional calculations needed to temporally anti-distort the generated hashes would be so obscene in both count size and compute size (you would need to have monitored the exact CPU state and timings of each computation, which is most intractable to say the least, even for insiders like Starfleet engineers), that simply put, no one would ever actually 'bother you' about it... They would essentially be searching an infinitessimal part of the combinatorial search space, for half of 'universal eternity', and making no progress... Kinda like a Terran trying to explain euphoria to a vulcan with much badly hidden schadenfreude, and then realising with excruciating abasement, that upon talking to your average Andorian later that evening, Terran euphoria is like comatosis in comparison to Andorian 'Raptulation'!!!... What is more, the dilation of the time-space continuum (see later in this algorithm) which occurs when using this algorithm, has been theorised as the source of Bynar free-will... It may actually boost the combinatorial search space up to (10^40)^10) or 10^400, which gives Bynars the ability to make anywhere up to ten centillion possible decision variants in their lifetime!!!... They claim that Terrans enjoy considerably less largesse, and for obvious reasons, no hate intended!!!... Don't quote me on these stats (I can't be bothered to actually work them out... Besides, there is a conceptual and philosophical debate yet to be had, surrounding the difference between combinatorial and complexial algorithm stats!!!)

--Please note, that the reason I have chosen the Pi number as the basis of randomicity is as follows:
--The digits of π (pi) are basically the universe's best 'foundationally intrinsic' attempt to provide mankind with the perfect random sequence generator.. Here’s a breakdown of why:
--1. π (pi) is Deterministic --> Which is necessary, in order to actually compute a reliable output.
--2. The classes of π (pi) are Uniformly Distributed --> This means that in the known decimal expansions, each digit (0 to 9) appears roughly equally often.
--3. The sequence of π (pi) digits is Statistically Random --> Ideal, because there are no obvious meta-patterns that repetitively occur.
--4. The limit of π (pi) is Normal --> Basically indicating, that its infinite decimal expansion will propagate the first three properties with the utmost fidelity.
--5. Simulated Chaos arising from deconstructed π (pi) derivations --> Should however, mean that small changes in global variables, can emulate maximally possible quantum-random behaviour on digital hardware.
--In conclusion, I would stop using all other random integer generators pronto, and come join +Raphael+ in the superiority-takes-all space conquest... It starts with Terran-operated bases on the moon this decade, and is quickly followed up by speciating-humanoid colonies on Mars, this half century!!!

--Please note, that during very minimal testing, repeated executions of the query, while temporal distortion was engaged, sometimes generated the same Hash IDs... I can only imagine that this is because query caching is turned on... Please remember to disable query caching for this algorithm, if you are using temporal distortion features!!!... Of course, once the query has cached as temporally distorted, and you amend the associated toolean global variables, query caching will likely also adversely affect the desired output from the algorithm... SO PLEASE ALWAYS TURN OFF QUERY CACHING INFACT!!!
--Also, please note, that due to SQL Server data type precision and clock timing precision shortcomings, both hashes and numbers that are served, do not include the capability of varying across the single most precsise digit ('ones')... In practice, this means we are waiting on Microsoft to improve SQL Server precision in order to unlock full and true pseudo-quantum randomicity generation... For now, if you use the algorithm, you will only experience randomicit granularity every 10 degrees of algorithmic freedom (ie_ every ten consecutive integer numbers on the 100,000,000 range scale {as the numbers inbetween will not currently be modelled})... This invariability is actually nugatory, because the number 10 is so small compared to 100,000,000, and so will simply be almost always rounded out of effect...

--I now consider this algorithm functionally complete, in terms of being able to model any kind of randomicit series of Hash IDs / Numbers / Labels (You would simply use a Replace() function on the resulting random numbers, which correspond to your label classes {provided you have set the range bounds appropriately})... As such, if the functionality that you believe you require doesn't exist in this algorithm, you are probably trying to generate randomicity for the wrong reasons!!!
--I also have theories regarding next-generation completely-superior advanced usecases for random number generators (algorithm blueprints designed already)... More on this, once I get a job or a customer...
--One idea I will providing a solution for can be called something like Native Augmentable Physics Simulation (NAPS)... This is a trick I learned from Master Jedi 'Yoda the Best' himself!!!

--(NECESSARY METAVARIABLE SETTINGS)
--I would like a setting to turn of query caching for all plans in this query, without having to specify for individual statements, and I certainly don't want to turn of query plans for the whole database... Come on Microsoft... Why have you not already enabled this functionality???... It seems pretty universally useful!!!...


--(GLOBAL VARIABLES)
-->>>>>>>>>>>>>>>>> EVERY TIME YOU EXECUTE THIS ALGORITHM, PLEASE AT A MINIMUM, REMEMBER TO CHECK THAT THESE THREE VARIABLES ARE SET CORRECTLY BELOW, IN THE APPROPRIATE ASSIGNATION CODEBLOCK!!!!!
--1. Temporal_Distortion_Boolean
--2. Range_Bounded_Number_Generation_Boolean
--3. Range_Bound_Frequency_Boolean
--<<<<<<<<<<<<<<<<<  EVERY TIME YOU EXECUTE THIS ALGORITHM, PLEASE AT A MINIMUM, REMEMBER TO CHECK THAT THESE THREE VARIABLES ARE SET CORRECTLY BELOW BELOW, IN THE APPROPRIATE ASSIGNATION CODEBLOCK!!!!!

--1. Random Hashes Variables
Declare @Hash_Seed_Terran Bigint
Set @Hash_Seed_Terran = 17 --1 >= x <= 100,000,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Terran Hash Seed value must be different from the Vulcan and Andorian Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Seed_Vulcan Bigint
Set @Hash_Seed_Vulcan = 4000 --1 >= x <= 100,000,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Vulcan Hash Seed value must be different from Terran and Andorian Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Seed_Andorian Bigint
Set @Hash_Seed_Andorian = 831228 --1 >= x <= 100,000,000,000 ... Nota Bene: The lower the Hash Shift, the more likely it is that you will want a lower Hash Seed value... The Andorian Hash Seed value must be different from Terran and Vulcan Hash Seed values, in order to avoid a Starfleet civil war!...

Declare @Hash_Shift Bigint
Set @Hash_Shift = 6 --1 >= x <= 10 ... Lower hash shift values will produce more randomicit integer hashes at smaller hash lengths; whereas, larger hash shift values will lead to more randomicit consecutive repetitions of integer hashes at larger hash lengths... This mechanism is a trade-off... If you are unsure which value to use, simply set the value to 1 for default behaviour which is more similar to exisiting class-probability-balanced random number generators... Nota Bene: The higher the Hash Seeds, the more likely it is that you will want a higher Hash Shift value... My advice, is experiment a little!... Disclaimer: I'm not even entirely sure if this variable control is really all that useful outside of theory, and haven't been able to test it in an applied manner, to my usual satisfaction and significance criteria...

Declare @Hash_Value_Length Bigint
Set @Hash_Value_Length = 40 --1 >= x < 8,000... Any longer, and I fear that you may be up to something quite dangerous to the strategic goals of Starfleet!!!

Declare @Hash_Array_Length Bigint
Set @Hash_Array_Length = 1000 --1 >= x < As big as y're rig can handle... But, saying that, there is actually a precision limit which would eventually gradually nugify your Hash IDs at some point, as you increase Hash Array Length... The greater the data type precision they release for SQL Server, the greater this variable value can be... For now, I would not recommend any value above 1,000 (Although this is probably unnecessarily conservative)...

Declare @Temporal_Distortion_Boolean Tinyint
Set @Temporal_Distortion_Boolean = 1 --PLEASE BE AWARE: You shouldn't use the temporal distortion feature here, if you require repeatability as a property of your outputs... If repeatanbility is required, then set this variable to zero (0)... Otherwise to one (1) in order to engage temproal distortion...

Declare @Temporal_Distortion_Flange As Tinyint
Set @Temporal_Distortion_Flange = 33 --Standard protocol flange would be around 50%, with recommended range from 33% to 66%, and limits at 0% and 100%... This basically controls how much Hash Seed values get temporally distorted...

--2. Random Numbers Variables
Declare @Range_Bounded_Number_Generation_Boolean Tinyint
Set @Range_Bounded_Number_Generation_Boolean = 1 --This variable can be set to either zero (0) --> random hash IDs will be generated... Or, it can be set to one (1) --> random integer numbers will be generated, according to the range bounds set on the @Obsidian_Range_Bounds global table variable below...
--Automatic override of the @Hash_Value_Length global variable from above...
If @Range_Bounded_Number_Generation_Boolean = 1
	Begin
		Set @Hash_Value_Length = 8 --You can only currently generate random numbers on a scale from zero to around nine pentillion (0 to 9,223,372,036,854,775,807) {limited only really by the Bigint data type max value... Otherwise, theoretically, one could generate random numbers with up to hundreds of billions or more digits with this algorithm}, with no highest precison variability in the 'ones' digit, due to SQL Server data type precision and CPU clock timing precision restrictions... In other words, there will always be a jump of 10 consecutive integers between each generated integer number or hash ID, from a perspective of varying the scale index, although, as mentioned elsewhere, this lack of granular variability is actually miniscule, given the massive size of the randomicit hash range (100,000,000) compared to the invariability range (10), and so almost always will have no effect...
	End

--Please note, that boundary values here below must be between around negative nine pentillion (-9,223,372,036,854,775,807) and around positive nine pentillion (9,223,372,036,854,775,807) inclusive... Also, even if range bounds are duplicate or overlapping, this will be carefully handled later on, so don't worry too much about this aspect!!!... Like I have said here, this algorithm can also handle negative integer range bounds, but just make sure that you have the bound values in the right order (The [Lower_Bound] column {most negative of the pair of bound values --> furthest from zero in the negative scale} and then the [Upper_Bound] column {least negative of the pair of bound values --> furthest from zero in the positive scale})
--Frequencies are comparative, and so normalise against eachother onto a 100% probability scale... As such, this column can hold either whole numbers (with their decimals all set to zero), or fractional numbers... It's up to you... If you simply want to use a standard frequency for certain rows, the @Default_Frequency_Value variable can be used, as demonstrated... To get vanilla default behaviour ie_ no frequency skewing of the classes, then you have three options... Either: 1. Set the @Range_Bound_Frequency_Boolean variable value to zero (0)... or... 2. Set all frequencies to the same value (Ideally the number one {1})... or... 3. Set all frequencies to the @Default_Frequency_Value variable...
Declare @Range_Bound_Frequency_Boolean As Tinyint
Set @Range_Bound_Frequency_Boolean = 1 --Can turn frequency distribution adjustment off, by assigning a value of zero (0)... Or on, by assigning a value of one (1)...

Declare @Default_Frequency_Value As Decimal(38, 19) --We restrict the [Frequency] value onto a 0,000,000,000,000,000,000.000000 digit-scale... Please make sure that you normalise your [Frequency] values in the table @Obsidian_Range_Bounds (along with the variable @Default_Frequency_Value), so that they are all positive values that are less than or equal to 9,223,372,036,854,775,807... and no zero only values please, otherwise they will not receive any manifestation...
Set @Default_Frequency_Value = 100.00 --Don't adjust this value (don't change it to something other than one hundred percent (100.00)), unless you know what you're doing!!!... You don't even need to use this variable at all, unless you are an advanced user...

Declare @Obsidian_Range_Bounds Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19)) --We restrict the [Frequency] value onto a 0,000,000,000,000,000,000.000000 digit-scale... Please make sure that you normalise your [Frequency] values in the table @Obsidian_Range_Bounds (along with the variable @Default_Frequency_Value), so that they are all positive values that are less than or equal to 9,223,372,036,854,775,807... and no zero only values please, otherwise they will not receive any manifestation...
Insert Into @Obsidian_Range_Bounds ([Lower_Bound], [Upper_Bound], [Frequency])
--I'm advising users to set the lower and upper bounds to the same value, only if you want to configure a bound for a single integer value instead of a contiguous range of values... Should have been obvious, but I know that under high stress and time pressures, that from experience, software operators lose insight with regards to trivial things like this!
Values
(-2, 0, 100),
(0, 2, 100),
(-500, -496, 10),
(1000000, 1000004, 10)


--(PART A: HASH EXECUTION)
--The following If statement helps to avoid unnecessary compute...
If @Temporal_Distortion_Boolean != 0
	Begin

		--Temporal Distortion Priming
		--When a hash seed is low, ie below 50 Million, then you probably would want a positive temporal distortion, for obvious reasons... But, when hash seed is high howver, i.e. above 50 Million, then you probably would benefit more from setting a corresponding negative temporal distortion, if any at all in either case...
		--(Terran)
		Declare @Temporal_Distortion_Toolean_Terran Int
		If @Hash_Seed_Terran <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Terran = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Terran > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Terran = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		--(Vulcan)
		Declare @Temporal_Distortion_Toolean_Vulcan Int
		If @Hash_Seed_Vulcan <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Vulcan = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Vulcan > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Vulcan = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		--(Andorian)
		Declare @Temporal_Distortion_Toolean_Andorian Int
		If @Hash_Seed_Andorian <= 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Andorian = 1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...
		Else If @Hash_Seed_Andorian > 50000000 --50 million is half the Hash Seed range...
			Set @Temporal_Distortion_Toolean_Andorian = -1 --Can be set to either the number minus one (negatively engaged) or the number one (positively engaged)... This feature has been injected directly into the seeds, rather than into the Hash ID serving transformation below, due to the desire to minimise unnecessary compute.. With the seeds being distorted, it only takes three very simple computations, whereas with the servings being distorted, the additional computational load could be unacceptable due to the exponential nature of that part of the algorithm (which I hasten to add, would infact provide more computational complexity, but no more additonal cyber security, as opposed to simply distorting the seed values)...


		--Temporal_Distortion
		Declare @Current_System_State_Clock_Index_Partition As Varchar(8)
		Set @Current_System_State_Clock_Index_Partition = Right(Replace(Replace(Replace(Replace(Cast(Sysutcdatetime() As Varchar(Max)), '-', ''), ' ', ''), ':', ''), '.', ''), 8) --I have partially 'reverse sliced' the granularity here (the 'full reversing' takes place later on in the algorithm), because for my database, the year comes first in this value, and the greatest precision seconds decimal comes last... Whereas, you always want the least geranularity last (the year segment), and the greatest granularity first (the highest precision sub-second)... If you do not properly handle this dynamic (which arises due to different datetime2 formats across different databases, when calling the Sysutcdatetime() function), then your temporal distortion will be less than ideal, and possibly pointless, in terms of maximising cyber security protections... Nota Bene: In this current implementation, we are only using part of the Sysutcdatetime() function Datetime2 output value (This will need to be amended in cases where greater Hash Seed data type precisions are enabled in SQL Server)...
		--This temporal dilator technique must use fractional numbers up to and including the first seconds digit (from greatest decimal precision digit up to single digit seconds, which in this case provides 8 consecutive digits), but no more than this, such as also using hours or days etc_, because otherwise the temproal distortion would be biased and potentially easier to cyber hack (hours for example, don't cover all numbers between zero and ninety nine... they only cover twenty four at most, which means the distribution of outputs would be skewed to lower numbers {Especially in the less precise hour digit}...)...
		
		--We use an zero injection technique later on in the algorith (in the clock index rebuild), in order to boost the dynamic nature of the temporal randomicit distortion... Otherwise, most distortions would either be very close or very far from the original Hash Seed values...
		Declare @Normalised_Zero_Injection_Count As Tinyint
		Set @Normalised_Zero_Injection_Count = Round((((Cast(Substring(@Current_System_State_Clock_Index_Partition, 8, 1) As Decimal(38, 37)) / Cast(10 As Decimal(38, 36))) * Cast(7 As Decimal(38, 37))) * (Cast((100 - @Temporal_Distortion_Flange) As Decimal(38, 35)) / Cast(100 As Decimal(38, 35)))), 0) --We use the greatest precision limit integer to decide how many zeroes we are injecting into the clock index (so that we can later fully utilise the full Hash Seed range when temporally distorting)... Otherwise, only very small temporal perturbations would occur (due to most numbers in the Hash Seed range being in the tens of millions), which would significantly reduce the cyber defensive power of this temporal distortion technique... The range from zero to nine (0 to 9), has been balanced out, by dividing with a value of 10 {called proportional or output normalisation}... Please also note, the alteration from the typical Decimal(38, 37) {which would have worked with an upper range limit of nine (9)}, but because we now have an upper range limit of ten (10), we need to use the {Decimal(38, 36)} data type here, in order to avoid arithmetic overflows or something like that, where the number can't be stored as it is larger than the variable data type)... We normalise onto a scale from one to seven, for obvious reasons (divide zero errors and misaligned ranges {we currently only want eight digits in our distortion capability (with no possibility of producing an overall zero), whereas eights and nines could appear some times, unless we normalise them out})... We also implement the tmeporal distortion flange technique here, in order to reduce the degree of zero injection according to the degree of flange (This will give our output Hash Seeds more dynamicism, because they can be promoted to change more {At higher flanges}, depending on the same inputs)...
		
		--Manual transformation step I know, but its only 8 values right now, given the size of the Hash Seed ranges... Speak to a Catholic priest if this shortcut upsets you...
		Declare @Temporal_Distortion_Index Table ([Order] Tinyint, [Clock_Index] Tinyint)

		--Rebuild of the clock index
		Declare @Loop_Count_0001 As Tinyint
		Set @Loop_Count_0001 = 0
		--This following loop basically injects the zeroes...
		While @Loop_Count_0001 < 8 --Eight is the 'reverse sliced' clock index length...
			Begin
		
				Set @Loop_Count_0001 = (@Loop_Count_0001 + 1)
				
				--Unfortunately, here in the sourcecode, in the conditional if statement below, that rebuilds the clock index... Because of lack of system datetime precision, the last clock index integer is used in order to determine how many zeroes are injected, and it currently would also need to be re-used here (for full spectrum coverage... ie_ single digit integer flexibility in the outputs, instead of simply always putting a zero in the last position of the rebuilt clock index), but this seems conceptually polluted in some minor way to me right now (as it would result in always producing the same number (8) anyway, when the most precise datetime decimal digit is an 8)... Despite the implemented fudge, you could argue, that it would almost always get rounded out anyways, due to the large hash seed range size, and really precise class granularity... FINALLY ON THIS POINT: The fudge is concerning, but so long as the global  @Temporal_Distortion_Flange variable is kept above 33%, the fudge edge case should rarely materialise (1.59% chance ChatGPT thinks... not sure...)... Possibly...
				If @Loop_Count_0001 <= @Normalised_Zero_Injection_Count
					Begin
						Insert Into @Temporal_Distortion_Index ([Order], [Clock_Index])
						Values (Cast(@Loop_Count_0001 As Tinyint), Cast(0 As Tinyint))
					End
				Else If @Loop_Count_0001 > @Normalised_Zero_Injection_Count
					Begin
						Insert Into @Temporal_Distortion_Index ([Order], [Clock_Index])
						Values (Cast(@Loop_Count_0001 As Tinyint), Cast(Substring(@Current_System_State_Clock_Index_Partition, (8 - @Loop_Count_0001), 1) As Tinyint)) --(8 - @Loop_Count_0001) because you want to always use the most dynamic and frequently changing digit integers first, after leaving out the greatest precision digit integer in position eight, which was used to generate a number of zeros injection value previously...
					End
			End
		
		--This codeblock fully rebuilds...
		Declare @Current_System_State_Clock_Index_Partition_Rebuilt As Varchar(8)
		Set @Current_System_State_Clock_Index_Partition_Rebuilt = Cast((Select String_Agg(Cast([Clock_Index] As Varchar(8)), '') Within Group (Order By [Order] Asc) As [Zero_Injected_Clock_Index] From @Temporal_Distortion_Index) As Varchar(8)) --Just an acknowledgement of algorithmic shortfall here, but because SQL Server doesn't provide date time data types with at least 8 digit decimal precision (it currently maxes out at 7 digits), we never actually distort hash seeds using the single digit integer position (there will currently always be a trailing zero)... Not ideal, but arguably okay, because you probably want greater time distortions anyways...

		--We can now distort our hash seeds appropriately, as follows...
		Declare @Temporal_Distortion_Granularity_Step_Size As Decimal(38, 29)
		Set @Temporal_Distortion_Granularity_Step_Size = (Cast(@Current_System_State_Clock_Index_Partition_Rebuilt As Decimal(38, 30)) / Cast(99999999 As Decimal(38, 30))) --Please make sure that this 100 million value remains in synchronisation with the rest of the algorithm, if amending in any significant way (for example greater precision data types and therefore larger seed ranges)... Also make sure it is in synchronisation with the seed range limit data validation constraints (Which I haven't actually implemented here, but simply mentioned in the comments above)...

		--1. Terran Temporal Distortion
		If @Temporal_Distortion_Toolean_Terran = -1
			Begin
				Set @Hash_Seed_Terran = Floor((@Hash_Seed_Terran - ((@Hash_Seed_Terran - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Terran = 1
			Begin
				Set @Hash_Seed_Terran = Ceiling((@Hash_Seed_Terran + ((100000000 - @Hash_Seed_Terran) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End
		--2. Vulcan Temporal Distortion
		If @Temporal_Distortion_Toolean_Vulcan = -1
			Begin
				Set @Hash_Seed_Vulcan = Floor((@Hash_Seed_Vulcan - ((@Hash_Seed_Vulcan - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Vulcan = 1
			Begin
				Set @Hash_Seed_Vulcan = Ceiling((@Hash_Seed_Vulcan + ((100000000 - @Hash_Seed_Vulcan) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End
		--3. Andorian Temporal Distortion
		If @Temporal_Distortion_Toolean_Andorian = -1
			Begin
				Set @Hash_Seed_Andorian = Floor((@Hash_Seed_Andorian - ((@Hash_Seed_Andorian - 1) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Floor() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when negatively distorting via a subtraction operand on this line of sourcecode...
			End
		Else If @Temporal_Distortion_Toolean_Andorian = 1
			Begin
				Set @Hash_Seed_Andorian = Ceiling((@Hash_Seed_Andorian + ((100000000 - @Hash_Seed_Andorian) * @Temporal_Distortion_Granularity_Step_Size))) --We normalise the temproal distortion of the Hash Seed, by harmonising with the distance between the Hash Seed and its polar limit... The Ceiling() function is used here, in order to correctly handle decimal @Temporal_Distortion_Granularity_Step_Size values, when positively distorting via an addition operand on this line of sourcecode...
			End

		--Please note, that here below, I have set different temproal distortion modifiers for the three different Hash Seed distortions... This is highly advisable, given that the algorithm is not designed to work when any of the three Hash Seeds are identical!!!
		--Limit Modifier
		--(We here need to worry about modifying on the hash seed range limits, because it is assumed that a temporal distortion could cause all three hash seeds to clash onto either 1 or 100,000,000...)
		If @Hash_Seed_Terran = 1
			Begin
				If @Hash_Seed_Vulcan = 1
					Begin
						If @Hash_Seed_Andorian = 1
							Begin
								Set @Hash_Seed_Terran = 1
								Set @Hash_Seed_Vulcan = 2
								Set @Hash_Seed_Andorian = 3
							End
					End
			End
		Else If @Hash_Seed_Terran = 100000000
			Begin
				If @Hash_Seed_Vulcan = 100000000
					Begin
						If @Hash_Seed_Andorian = 100000000
							Begin
								Set @Hash_Seed_Terran = 99999998
								Set @Hash_Seed_Vulcan = 99999999
								Set @Hash_Seed_Andorian = 100000000
							End
					End
			End
		--Proximal Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Andorian = @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
			End
		--Distal Terran Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Andorian > @Hash_Seed_Terran
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
					End
				Else If @Hash_Seed_Andorian < @Hash_Seed_Terran
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran + 1)
					End
			End
		--Distal Andorian Modifier
		Else If @Hash_Seed_Andorian = @Hash_Seed_Vulcan
			Begin
				If @Hash_Seed_Terran > @Hash_Seed_Andorian
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian - 1)
					End
				Else If @Hash_Seed_Terran < @Hash_Seed_Andorian
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
			End
		--Inverted Modifier
		Else If @Hash_Seed_Terran = @Hash_Seed_Andorian
			Begin
				If @Hash_Seed_Terran > @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Andorian = (@Hash_Seed_Andorian + 1)
					End
				Else If @Hash_Seed_Andorian < @Hash_Seed_Vulcan
					Begin
						Set @Hash_Seed_Terran = (@Hash_Seed_Terran - 1)
					End
			End

	End


--Hash_Value_Scaffold
Declare @Dynamic_SQL_Data_Intermediate_Variable_Hash_Value As Nvarchar(Max)
Set @Dynamic_SQL_Data_Intermediate_Variable_Hash_Value =
(
'Declare @Number_Seeds Table ([Number_Seed] NvarChar(1))
Insert Into @Number_Seeds ([Number_Seed])
Values (''0''), (''1''), (''2''), (''3''), (''4''), (''5''), (''6''), (''7''), (''8''), (''9'') ' +
Replace(dbo.Obsidian_Element_Index_Generator_Code_Parallel_Super_Fast(@Hash_Value_Length), '@Index_Count', @Hash_Value_Length) --This algorithm can be found on my GitHub account in the same repository that you found this script in.
)

Declare @Obsidian_Index_Scaffold_Hash_Value Table ([Index] Int)
Insert Into @Obsidian_Index_Scaffold_Hash_Value ([Index])
Execute (@Dynamic_SQL_Data_Intermediate_Variable_Hash_Value)


--Hash_Array_Scaffold
Declare @Dynamic_SQL_Data_Intermediate_Variable_Hash_Array As Nvarchar(Max)
Set @Dynamic_SQL_Data_Intermediate_Variable_Hash_Array =
(
'Declare @Number_Seeds Table ([Number_Seed] NvarChar(1))
Insert Into @Number_Seeds ([Number_Seed])
Values (''0''), (''1''), (''2''), (''3''), (''4''), (''5''), (''6''), (''7''), (''8''), (''9'') ' +
Replace(dbo.Obsidian_Element_Index_Generator_Code_Parallel_Super_Fast(@Hash_Array_Length), '@Index_Count', @Hash_Array_Length) --This algorithm can be found on my GitHub account in the same repository that you found this script in.
)

Declare @Obsidian_Index_Scaffold_Hash_Array Table ([Index] Int)
Insert Into @Obsidian_Index_Scaffold_Hash_Array ([Index])
Execute (@Dynamic_SQL_Data_Intermediate_Variable_Hash_Array)


--Hash_Generation
Declare @Pillars_Of_Starfleet Table ([Array_Index] Bigint, [Value_Index] Bigint, [Scrambled_Eggs_Benedict] Varchar(Max), [A_Tiny_Mush_Of_Vulcan_Flan] Decimal(38, 37), [A_Huge_Slice_Of_Andorian_Pie] Decimal(38, 37))
Insert Into @Pillars_Of_Starfleet ([Array_Index], [Value_Index], [Scrambled_Eggs_Benedict], [A_Tiny_Mush_Of_Vulcan_Flan], [A_Huge_Slice_Of_Andorian_Pie])
Select
	A.[Index] As [Array_Index],
	B.[Index] As [Value_Index],
	Reverse(Cast(((Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 1))  - (Cast(2 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 4)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 5)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Terran - 1))) + 6))) As Varchar(Max))) As [Scrambled_Eggs_Benedict], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Terrans appreciate scrambled eggs for brunch (It is used mainly as a hangover cure, along with a bloody mary, after the exploits of a night 'out on the town'... Plus, a 'famous prophet' of the never ending millenium, has declared that Canadians will probably be all the rage, in some significant manner, during the first space age race!!!)... It's been reversed, as a warning to the 21st century youth, that booze binges lead to beer belly battlegrounds, where your stomach fights for survival, and may not actually be able to hold down a meal...
	((Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 1))  - (Cast(2 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 4)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 5)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Vulcan - 1))) + 6))) As [A_Tiny_Mush_Of_Vulcan_Flan], -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Vulcans don't really appreciate flan (It is used mainly as a penance during the rigours of Kolinahr!!!)...
	((Cast(4 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 1))  - (Cast(2 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 4)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 5)) - (Cast(1 As Decimal(38, 37)) / ((8 * ((((A.[Index] - 1) * @Hash_Value_Length) + B.[Index]) + (@Hash_Seed_Andorian - 1))) + 6))) As [A_Huge_Slice_Of_Andorian_Pie] -- We calculate a deconstructed derivation, inspired by the Bailey–Borwein–Plouffe (BBP) Formula, for approximating Pi... Andorians really appreciate pie (It is usually their main course in a meal!!!)...
From @Obsidian_Index_Scaffold_Hash_Array A
Cross Join @Obsidian_Index_Scaffold_Hash_Value B


--Hash_Servings
Declare @Hash_Servings Table ([Order] Bigint, [Firmament_Feast] Varchar(Max))
Insert Into @Hash_Servings ([Order], [Firmament_Feast])
Select
	[Array_Index] As [Order],
	String_Agg(Sqrt(Square(Cast(Substring(Reverse(Cast(([A_Tiny_Mush_Of_Vulcan_Flan] - [A_Huge_Slice_Of_Andorian_Pie]) As Varchar(Max))), (Case When ([Value_Index] % @Hash_Shift) = 0 Then @Hash_Shift Else ([Value_Index] % @Hash_Shift) End), 1) As Tinyint))), '') Within Group (Order By [Scrambled_Eggs_Benedict] Asc) As [Firmament_Feast] --We can now serve a tasty pseudo-random integer meal... Please be aware that there is currently no particular order in which the courses and their constituents are brought together (which is one of the main strengths of the algorithm... of course... excuse the pun...)... As such, there may be some usecases or circumstances where this is unacceptable (Starfleet Standard Issue Blitz Rations don't exactly make the mouth water, eh???)... Here, we also use an index modulo shift technique, in order to increase the randomicit features and behaviours of the algorithm (It activates the Hash Shift control)... The core 'flan' minus 'pie' method here, basically dilates the combinatorial search space by the power of 10, such that you now have a double nested exponent on the overall complexity of the algorithm!!!... Just as a side, but the spatial dialtion implemented here, by using the two pillar dimensions, could possibly be used as part of a model of the extreme dimensional characteristics of a black hole (In essence, there is theoretically no limit to the amount of spatial dilation that one could model)...
From @Pillars_Of_Starfleet
Group By [Array_Index]
Order By [Array_Index] Asc --You only need this line of code in SQL Server, because it handles data in no explicit order by default... If implementing in your own app or programming language, leave this out, as it simply would slow down the algorithm execution... Unless you also implement in a SQL RDBMS-like usecase...


--And so the three insatiable Starfleet God's of Gluttony are born into the cosmos: 1. Haon the Father of the Terrans; 2. Divad the brother of the Vulcans; and 3. Susej the friend of the Andorians...


--(PART B: NUMBER EXECUTION)
If @Range_Bounded_Number_Generation_Boolean = 1
	Begin
		
		Declare @Obsidian_Range_Bounds_Normalised Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(9,6))
		--Below, we normalise the digit range bounds onto a 100% [Frequency] scale, or we set all frequencies to 1.000000 (depending on the appropriate global variable, which activates distributive random sampling)...
		If @Range_Bound_Frequency_Boolean = 0
			Begin
				
				Insert Into @Obsidian_Range_Bounds_Normalised ([Lower_Bound], [Upper_Bound], [Frequency])
				Select
					[Lower_Bound] As [Lower_Bound],
					[Upper_Bound] As [Upper_Bound],
					1 As [Frequency] --Setting this value to one (1) across all rows, forces equal/balanced class distribution...
				From @Obsidian_Range_Bounds
			
			End
		Else If @Range_Bound_Frequency_Boolean = 1
			Begin

				Declare @Obsidian_Range_Bounds_Maximum_Frequency As Decimal(38, 19)
				Set @Obsidian_Range_Bounds_Maximum_Frequency = (Select Max([Frequency]) From @Obsidian_Range_Bounds)

				Insert Into @Obsidian_Range_Bounds_Normalised ([Lower_Bound], [Upper_Bound], [Frequency])
				Select
					[Lower_Bound] As [Lower_Bound],
					[Upper_Bound] As [Upper_Bound],
					Cast(([Frequency] / @Obsidian_Range_Bounds_Maximum_Frequency) As Decimal(9,6)) As [Frequency]
				From @Obsidian_Range_Bounds
			
			End

		--We remove all duplicate bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency]  Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct ([Lower_Bound], [Upper_Bound], [Frequency])
		Select Distinct
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Range_Bounds_Normalised

		--We anchor the bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Row_Number() Over(Order By (Select Null)) As [Anchor_Order], --I have used a null returning subquery within the ordering clause, as this seems to optimise for greatest speed... I think the SQL Server engine simply ignores the ordering clause in this case, which is the exact behaviour we want.
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct

		--We remove all subsidiary bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			A.[Anchor_Order] As [Anchor_Order],
			A.[Lower_Bound] As [Lower_Bound], 
			A.[Upper_Bound] As [Upper_Bound],
			A.[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored A
		Left Join @Obsidian_Bounds_Distinct_Anchored B
			On (
				B.[Anchor_Order] <> A.[Anchor_Order]
				And B.[Lower_Bound] <= A.[Lower_Bound]
				And B.[Upper_Bound] >= A.[Upper_Bound]
			)
		Where 
			B.[Lower_Bound] Is Null
			And B.[Upper_Bound] Is Null
	
		--We find the middle of chain overlapping bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Min(A.[Anchor_Order]) As [Anchor_Order],
			Min(B.[Lower_Bound]) As [Lower_Bound], 
			Max(B.[Upper_Bound]) As [Upper_Bound],
			Max(B.[Frequency]) As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds A
		Cross Join @Obsidian_Bounds_Distinct_Anchored_Superbounds B
		Where
			B.[Lower_Bound] >= A.[Lower_Bound]
			And B.[Lower_Bound] <= A.[Upper_Bound]
			Or
			B.[Upper_Bound] >= A.[Lower_Bound]
			And B.[Upper_Bound] <= A.[Upper_Bound]
		Group By A.[Anchor_Order]

		--We find the ends of chain overlapping bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Min(A.[Anchor_Order]) As [Anchor_Order],
			Min(B.[Lower_Bound]) As [Lower_Bound], 
			Max(B.[Upper_Bound]) As [Upper_Bound],
			Max(B.[Frequency]) As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle A
		Cross Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle B
		Where
			B.[Lower_Bound] >= A.[Lower_Bound]
			And B.[Lower_Bound] <= A.[Upper_Bound]
			Or
			B.[Upper_Bound] >= A.[Lower_Bound]
			And B.[Upper_Bound] <= A.[Upper_Bound]
		Group By A.[Anchor_Order]

		--We find all distinct chain bounds in the codeblock below.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct Table ([Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct ([Lower_Bound], [Upper_Bound], [Frequency])
		Select Distinct
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends

		--We anchor the final bounds in the codeblock below, for use later on in this query.
		Declare @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored Table ([Anchor_Order] Bigint, [Lower_Bound] Bigint, [Upper_Bound] Bigint, [Frequency] Decimal(38, 19))
		Insert Into @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored ([Anchor_Order], [Lower_Bound], [Upper_Bound], [Frequency])
		Select
			Row_Number() Over(Order By [Lower_Bound] Asc) As [Anchor_Order], --I have used a null returning subquery within the ordering clause, as this seems to optimise for greatest speed... I think the SQL Server engine simply ignores the ordering clause in this case, which is the exact behaviour we want.
			[Lower_Bound] As [Lower_Bound], 
			[Upper_Bound] As [Upper_Bound],
			[Frequency] As [Frequency]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct
		
		--The following codeblock counts the unique integer classes within the digit bounds provided to the function. They handle digit boundary overlaps and chains appropriately.
		Declare @Unique_Integer_Class_Limit Bigint
		Set @Unique_Integer_Class_Limit = 
		(
		Select 
			(Case When @Range_Bound_Frequency_Boolean = 1 Then Round(Sum(((([Upper_Bound] - [Lower_Bound]) + 1) * ([Frequency] * 100))), 0) Else (Case When @Range_Bound_Frequency_Boolean = 0 Then Sum((([Upper_Bound] - [Lower_Bound]) + 1)) Else Null End) End)
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored
		)

		--Here, we accumulate unique integer class counts, by building a meta range boundary series...
		Declare @Unique_Integer_Class_Meta_Range_Boundary_Series Table ([Anchor_Order] Bigint, [Cumulative_Integer_Class_Count] Bigint)
		--We insert a prefixial row, in order to properly handle the lowest range boundary later on in the randomicity serving technique...
		Insert Into @Unique_Integer_Class_Meta_Range_Boundary_Series ([Anchor_Order], [Cumulative_Integer_Class_Count])
		Values
		(0, 0)
		--We then insert the rest of the actual range boundary ancillary data, which is also used later on in the randomicity serving technique...
		Insert Into @Unique_Integer_Class_Meta_Range_Boundary_Series ([Anchor_Order], [Cumulative_Integer_Class_Count])
		Select
			A.[Anchor_Order] As [Anchor_Order],
			(Case When @Range_Bound_Frequency_Boolean = 1 Then Round(Sum((((B.[Upper_Bound] - B.[Lower_Bound]) + 1) * (B.[Frequency] * 100))), 0) Else (Case When @Range_Bound_Frequency_Boolean = 0 Then Sum(((B.[Upper_Bound] - B.[Lower_Bound]) + 1)) Else Null End) End) As [Cumulative_Integer_Class_Count]
		From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored A
		Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored B On
			(B.[Anchor_Order] <= A.[Anchor_Order])
		Group By A.[Anchor_Order]

	End

--Randomicity_Serving
Declare @Penultimate_Randomicity_Serving Table ([Order] Bigint, [Random_Meta_Range_Boundary_Index] Decimal(38, 19))
				

If @Range_Bounded_Number_Generation_Boolean = 0 --If you have set global variables to serve Random Integer Hash IDs
	Begin
		
		Select
			[Order] As [Order],
			[Firmament_Feast] As [Firmament_Feast]
		From @Hash_Servings
		Order By [Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio...
	
	End
Else If @Range_Bounded_Number_Generation_Boolean = 1 --If you have set global variables to serve Random Numbers (As defined in the @Obsidian_Range_Bounds global table variable)
	Begin
		
		If @Range_Bound_Frequency_Boolean = 0
			Begin

				Insert Into @Penultimate_Randomicity_Serving ([Order], [Random_Meta_Range_Boundary_Index])
				Select
					[Order],
					Cast(('0.' + [Firmament_Feast]) As Decimal(38, 19)) As [Random_Meta_Range_Boundary_Index] --We round our meta range boundary index to the nearest (greater than) whole integer (using the Ceiling() function), in order to get the overall index for the randomly selected number... This can then be used to map across all the ordered range boundaries from the global variable @Obsidian_Range_Bounds, and therefore return the correct random number...
				From @Hash_Servings
				
				Select
					A.[Order],
					Ceiling(((E.[Lower_Bound] - 1) + ((A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit) - B.[Cumulative_Integer_Class_Count]))) As [Random_Numbers] --We use the Ceiling() function to correct rounding errors...
				From @Penultimate_Randomicity_Serving A
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series B On
					(B.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Left Join @Unique_Integer_Class_Meta_Range_Boundary_Series C On
					(C.[Anchor_Order] > B.[Anchor_Order] And C.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series D On
					(D.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored E On
					(E.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Where C.[Anchor_Order] Is Null
				Order By A.[Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio...

			End
		Else If @Range_Bound_Frequency_Boolean = 1
			Begin

				Declare @Consolidated_Bound_Count As Bigint
				Set @Consolidated_Bound_Count = (Select Count(1) From @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored)

				Insert Into @Penultimate_Randomicity_Serving ([Order], [Random_Meta_Range_Boundary_Index])
				Select
					[Order],
					Cast(('0.' + [Firmament_Feast]) As Decimal(38, 19)) As [Random_Meta_Range_Boundary_Index] --We round our meta range boundary index to the nearest (greater than) whole integer (using the Ceiling() function), in order to get the overall index for the randomly selected number... This can then be used to map across all the ordered range boundaries from the global variable @Obsidian_Range_Bounds, and therefore return the correct random number...
				From @Hash_Servings

				Select
					A.[Order],
					Cast((Case When E.[Anchor_Order] = 1 Then Floor((Cast(E.[Lower_Bound] As Decimal(38, 19)) + (Cast((((E.[Upper_Bound] + Sqrt(Square(E.[Lower_Bound]))) - (E.[Lower_Bound] + Sqrt(Square(E.[Lower_Bound])))) + 2) As Decimal(38, 19)) * (Cast(A.[Random_Meta_Range_Boundary_Index] As Decimal(38, 19)) / Cast(E.[Frequency] As Decimal(38, 19)))))) Else (Case When E.[Anchor_Order] = @Consolidated_Bound_Count Then Floor((Cast((E.[Upper_Bound] + 1) As Decimal(38, 19)) - (Cast((((E.[Upper_Bound] + Sqrt(Square(E.[Lower_Bound]))) - (E.[Lower_Bound] + Sqrt(Square(E.[Lower_Bound])))) + 2) As Decimal(38, 19)) * ((1 - Cast(A.[Random_Meta_Range_Boundary_Index] As Decimal(38, 19))) / Cast(E.[Frequency] As Decimal(38, 19)))))) Else (Case When A.[Random_Meta_Range_Boundary_Index] <= Cast(0.5 As Decimal(38, 19)) Then Round((Cast((E.[Lower_Bound] - 1) As Decimal(38, 19)) + (Cast((((E.[Upper_Bound] + Sqrt(Square(E.[Lower_Bound]))) - (E.[Lower_Bound] + Sqrt(Square(E.[Lower_Bound])))) + 2) As Decimal(38, 19)) * (Cast(A.[Random_Meta_Range_Boundary_Index] As Decimal(38, 19)) / Cast(E.[Frequency] As Decimal(38, 19))))), 0) Else Round((Cast((E.[Upper_Bound] + 1) As Decimal(38, 19)) - (Cast((((E.[Upper_Bound] + Sqrt(Square(E.[Lower_Bound]))) - (E.[Lower_Bound] + Sqrt(Square(E.[Lower_Bound])))) + 2) As Decimal(38, 19)) * ((1 - Cast(A.[Random_Meta_Range_Boundary_Index] As Decimal(38, 19))) / Cast(E.[Frequency] As Decimal(38, 19))))), 0) End) End) End) As Bigint) As [Random_Numbers] --We normalise interboundary distance by using square and square root to make all these comparisons positive (otherwise if there is an inter-zero bound, the algorithm would fail to produce the positive specturm of numbers)... We modulate randomicity with 3 nested Case statements (otherwise, there is no way to handle bounds with different frequencies, because the bounds at the middle, upper, and lower end are incompatibile with eachother via the same calculation, due to the randomicit input values being naturally polarised in terms of their scale {0.9 will work completely opposite to 0.1, and so we need to handle the two halves and the possibly many middles with slightly different calculations})...--We use the Floor() and Round() functions in order to correct for rounding errors, which have possibly arisen when mathematically operating on mixed data types of Bigints and Floats... We also Cast( As Bigint), because of the unwanted injection of decimals from the [Random_Meta_Range_Boundary_Index] and [Frequency] terms... For some reason, adding two seems to work (not sure why at the moment, and I seriously can not be jibed to bother logicalising it, other than assuming that because we have used the Floor() and Round() functions, the outer limit classes must both be stretched for each range bound, otherwise you get rounding shrinkage of the the class distrinutions???)...
				From @Penultimate_Randomicity_Serving A
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series B On
					(B.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Left Join @Unique_Integer_Class_Meta_Range_Boundary_Series C On
					(C.[Anchor_Order] > B.[Anchor_Order] And C.[Cumulative_Integer_Class_Count] < (A.[Random_Meta_Range_Boundary_Index] * @Unique_Integer_Class_Limit))
				Inner Join @Unique_Integer_Class_Meta_Range_Boundary_Series D On
					(D.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Inner Join @Obsidian_Bounds_Distinct_Anchored_Superbounds_Overlap_Chain_Middle_Ends_Distinct_Anchored E On
					(E.[Anchor_Order] = (B.[Anchor_Order] + 1))
				Where C.[Anchor_Order] Is Null
				Order By A.[Order] --Unnecessary clause, because we have an order column... Just using it to display the results properly in SQL Server management studio...
			
			End
		
	End
