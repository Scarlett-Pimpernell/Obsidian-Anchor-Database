MAJOR_ANNOUNCEMENT_FOR_ALL_COMPUTER_SCIENTISTS_DEVELOPERS_ENGINEERS_AND_OPERATORS

!!!!!>>>>>This is the #Advent of Map-Reduce Learning (A branch of computer science machine learning)<<<<<!!!!!

I have just this night, fully realised the paradigm discontinuity with regards to these sorting algorithms, and how they should completely impact and disrupt, all software related strategy, tactics, operations, and grunt-work, worldwide.

Please focus on completely re-architecting your databases and programming languages, to run using Obsidian Partition Maps, similar to those implemented in these sorting algorithms.

You will almost certainly obtain tens, hundreds, or even thousands of multiples, of speed-ups, especially for big data usecases (billions of datapoints) and hyper data usecases (trillions of datapoints).

Essentially, all data selects, data inserts, data updates, and data deletes, as well as their equivalents in other databases and programming languages, should all leverage Obsidian Partition Maps, which execute on data which is natively stored in partitions/sub-tables.

...and remember the end-game... Multiple serial executions of Obsidian Partition Maps, which navigate down through a meta-data-structure of nested partitions/sub-tables, where each level of nesting is based on a different data column in the base dataset level tables...

... But stick to single level partitions as a first attempt. Get that working reliably, because nesting partitions/sub-tables from the start, will probably be very complex and difficult to do, without a basic working and optimised single partition/sub-table level approach.

... Further clarifications 0001... When a data transaction is handled by the database/programming language, the corresponding array of data should be split up into transactionlet partitions, using an appropriate Obsidian Partition Map...

... the data engine should simultaneously launch these partitioned 'transactionlets' through the navigation process, and as each reaches its destination at the deepest base level storage partition, the appropriate data edit method (siud) should be triggered to execute as a parallel batch...

(... Oh, and BTW... apply the Obsidian Partition Map approach to Large Language Models (#LLMs), and all of a sudden, you will have almost free inference!!!)

Oh, and remember the 1% 'mandatory' #Obsidian_Levy!

Ciao for now,

'The New Michelangelo', +Raphael+, xPetrus Romanusx, ^Sichula^, $Sinyangwe$

... pssst...

... I hear that partition keys may come in handy...

... Who knows?...

... One More Kicker For the Kiddos: There are many situations where engineers will want to check whether a value exists or doesn't exist... You can provide them with something I call 'Lazy Checkers', in order to optimise these kinds of requirements while fully leveraging Obsidian Partitions... Lazy Checkers work by providing a guarantee that a value does NOT exist if its corresponding combination of nested partitions does NOT exist (even without needing to check for the presence of the actual value in the deepest/lowest nesting level of the partition tree, which could potentially be a very expensive check when dealing with massive amounts of data)... Conversely, you can guarantee that a value MAY exist if its corresponding combination of nested partitions DOES exist (even without needing to check for the presence of the actual value in the deepest/lowest nesting level of the partition tree; you would typically then do some other expensive logic, before coming back to check if the value actually exists, by scanning the ultimate base partition where all the data is stored)...

(Long Temporal Gap)

Urm, I've been doing some more new year's thinking here... You may find that the existing SQL B-Tree index, is useful when used only directly on the Obsidian partitions, rather than also on the underlying data (it would clearly be stupid to use b-tree indexes on the underlying data if it has already been Obsidian partitioned!... bUt yeah, don't quote me necessarily, because I haven't tested it yet, but I do have strong reason to believe, that applying existing SQL B-Tree Index functionality to the partition levels alone, could significantly speed up a lot of computations... INFACT, UPON EVEN FURTHER THOUGHT, IT MAY BE EVEN MORE PERFORMANT THAN THE AFOREMENTIONED (B-TREES ON OBSIDIAN PARTITION MAP PARTITIONS), TO INSTEAD, FILTER OR SEARCH PARTITION LEVELS, BY USING OBSIDIAN PARTITION MAPS OF OBSIDIAN PARTITION MAP PARTITIONS (MAYBE WITH SLIGHTLY DIFFERENT GLOBAL VARIABLES, DEPENDING ON THE TYPE OF OBSIDIAN PARTITION MAP THAT IS BEING NAVIGATED)... I THINK THIS OPPORTUNITY REQUIRES AN IN DEPTH STUDY OR TWO!!!

… THE DREAM???: Recursive Obsidian Partition Maps, of each level of the Obsidian Partition Map navigation tree, for each table of data that has been partitioned.

… Now that would be true livin'!

… Nudge, nudge... You'll probably want to recurse at each level of the partition navigation tree, using one of the - Text Obsidian Partition Maps (with a slightly different stem length or pattern length each time)…

… This cool software trick (search partition maps applied to each level of the navigational partition maps) is useful when applied to decimal, text, and date partitions, because these types tend to generate large numbers of partitions, which could potentially be very slow to search through, in and of themselves, despite speeding access to their underlying base data!